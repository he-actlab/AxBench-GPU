FANN_FLO_2.1
num_layers=3
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=3 17 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.26970636844635009766e+00) (1, -2.98493409156799316406e+00) (2, 4.22503709793090820312e-01) (0, -4.69377374649047851562e+00) (1, 6.08121216297149658203e-01) (2, 1.31204366683959960938e+00) (0, -3.91858339309692382812e+00) (1, 9.31794464588165283203e-01) (2, 2.55470180511474609375e+00) (0, -2.69907045364379882812e+00) (1, 3.25125122070312500000e+00) (2, 5.20047760009765625000e+00) (0, -9.86361801624298095703e-01) (1, -3.70215845108032226562e+00) (2, 5.20876884460449218750e-01) (0, -1.32008004188537597656e+00) (1, -2.98764753341674804688e+00) (2, 3.91768902540206909180e-01) (0, -3.15477752685546875000e+00) (1, 2.13560032844543457031e+00) (2, 1.06727910041809082031e+00) (0, -3.10239386558532714844e+00) (1, 3.53695106506347656250e+00) (2, 3.60061597824096679688e+00) (0, -2.96207523345947265625e+00) (1, 2.02613949775695800781e+00) (2, 1.67585277557373046875e+00) (0, -3.81790328025817871094e+00) (1, -3.02619266510009765625e+00) (2, 2.11596339941024780273e-01) (0, -3.46417284011840820312e+00) (1, 3.36640334129333496094e+00) (2, 2.39707899093627929688e+00) (0, -1.31838202476501464844e+00) (1, -1.72770786285400390625e+00) (2, 1.88981592655181884766e+00) (0, -5.42214202880859375000e+00) (1, 6.63264393806457519531e-02) (2, -2.61361777782440185547e-01) (0, -1.59111726284027099609e+00) (1, 5.88481092453002929688e+00) (2, -1.02581942081451416016e+00) (0, -4.16431140899658203125e+00) (1, -1.47368407249450683594e+00) (2, 3.70213508605957031250e-01) (0, -3.73485541343688964844e+00) (1, 4.89784598350524902344e-01) (2, 1.61485648155212402344e+00) (3, 7.66747236251831054688e-01) (4, 6.65972650051116943359e-01) (5, 6.64355456829071044922e-01) (6, 3.42567175626754760742e-01) (7, 2.96089500188827514648e-01) (8, 1.75874185562133789062e+00) (9, 9.06458258628845214844e-01) (10, 3.11980038881301879883e-01) (11, 8.67645800113677978516e-01) (12, 2.63988304138183593750e+00) (13, 3.32772463560104370117e-01) (14, -2.22663378715515136719e+00) (15, 1.40619361400604248047e+00) (16, 7.99723982810974121094e-01) (17, 1.18144237995147705078e+00) (18, 5.75198829174041748047e-01) (19, 3.66071909666061401367e-01) (3, 2.09851694107055664062e+00) (4, 1.99121415615081787109e+00) (5, 1.79841423034667968750e+00) (6, 1.51264345645904541016e+00) (7, 1.34919345378875732422e+00) (8, 2.82720780372619628906e+00) (9, 2.33286881446838378906e+00) (10, 1.50458705425262451172e+00) (11, 2.24168157577514648438e+00) (12, 3.82194352149963378906e+00) (13, 1.63983762264251708984e+00) (14, 6.48780107498168945312e-01) (15, 2.40963077545166015625e+00) (16, 2.83841609954833984375e+00) (17, 2.91774487495422363281e+00) (18, 2.10338163375854492188e+00) (19, 7.62318789958953857422e-01) (3, 7.30937337875366210938e+00) (4, 5.46283912658691406250e+00) (5, 6.72222614288330078125e+00) (6, 6.65234327316284179688e+00) (7, 7.38088035583496093750e+00) (8, 7.17007875442504882812e+00) (9, 6.71988964080810546875e+00) (10, 6.72803497314453125000e+00) (11, 6.69394254684448242188e+00) (12, 9.27855300903320312500e+00) (13, 6.80205631256103515625e+00) (14, 5.91148996353149414062e+00) (15, 8.26803970336914062500e+00) (16, 6.77228212356567382812e+00) (17, 9.26119327545166015625e+00) (18, 5.42535257339477539062e+00) (19, 5.42250347137451171875e+00) 
