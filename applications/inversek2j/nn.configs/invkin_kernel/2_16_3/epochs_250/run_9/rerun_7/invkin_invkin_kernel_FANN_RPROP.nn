FANN_FLO_2.1
num_layers=3
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=3 17 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.17555034160614013672e+00) (1, -1.91220116615295410156e+00) (2, 5.33511579036712646484e-01) (0, -2.98383975028991699219e+00) (1, 5.22700929641723632812e+00) (2, 1.03658497333526611328e+00) (0, -4.35699129104614257812e+00) (1, 4.71365690231323242188e-01) (2, 4.02462005615234375000e-01) (0, -5.24651718139648437500e+00) (1, -1.13605058193206787109e+00) (2, 2.13362991809844970703e-01) (0, -1.47962164878845214844e+00) (1, 3.13397955894470214844e+00) (2, 7.58827745914459228516e-01) (0, -3.77853298187255859375e+00) (1, 1.43596872687339782715e-01) (2, 3.21105957031250000000e+00) (0, -2.77596163749694824219e+00) (1, 2.46048879623413085938e+00) (2, 1.68616428971290588379e-01) (0, -8.38234722614288330078e-01) (1, -1.70549321174621582031e+00) (2, 8.90087127685546875000e-01) (0, -4.35187435150146484375e+00) (1, -2.48555445671081542969e+00) (2, -5.00579953193664550781e-01) (0, -3.07479834556579589844e+00) (1, 1.94497716426849365234e+00) (2, 1.61083698272705078125e+00) (0, -1.56198227405548095703e+00) (1, 4.02974319458007812500e+00) (2, 3.71071755886077880859e-01) (0, -9.30422425270080566406e-01) (1, -4.41884469985961914062e+00) (2, 3.18068981170654296875e-01) (0, -4.48543119430541992188e+00) (1, 4.10801410675048828125e-01) (2, 3.33698004484176635742e-01) (0, -3.59064292907714843750e+00) (1, 1.04162704944610595703e+00) (2, 1.43709909915924072266e+00) (0, -2.44099283218383789062e+00) (1, 5.20432329177856445312e+00) (2, 2.06830835342407226562e+00) (0, -2.85265660285949707031e+00) (1, 2.22134137153625488281e+00) (2, 1.58074808120727539062e+00) (3, 7.78162717819213867188e-01) (4, 3.00609499216079711914e-01) (5, 7.83200025558471679688e-01) (6, 1.03725850582122802734e+00) (7, 5.22105991840362548828e-01) (8, -2.18158021569252014160e-01) (9, 1.32161080837249755859e+00) (10, -5.47864317893981933594e-01) (11, 1.99829697608947753906e+00) (12, 5.38715243339538574219e-01) (13, 7.06027030944824218750e-01) (14, 3.67695403099060058594e+00) (15, 8.88626337051391601562e-01) (16, 6.32015526294708251953e-01) (17, 2.48222604393959045410e-01) (18, 5.68840563297271728516e-01) (19, -3.58135551214218139648e-02) (3, 2.85023236274719238281e+00) (4, 1.48236560821533203125e+00) (5, 1.87723624706268310547e+00) (6, 2.67178177833557128906e+00) (7, 1.51886844635009765625e+00) (8, 8.59309732913970947266e-01) (9, 2.57108759880065917969e+00) (10, 2.62381982803344726562e+00) (11, 3.54851579666137695312e+00) (12, 1.62892937660217285156e+00) (13, 2.01582169532775878906e+00) (14, 6.00687170028686523438e+00) (15, 2.00808405876159667969e+00) (16, 2.21924424171447753906e+00) (17, 1.45463728904724121094e+00) (18, 1.82822632789611816406e+00) (19, 7.19237029552459716797e-01) (3, 1.11377325057983398438e+01) (4, 5.81836271286010742188e+00) (5, 5.52302551269531250000e+00) (6, 9.23590564727783203125e+00) (7, 5.79637289047241210938e+00) (8, 5.77769708633422851562e+00) (9, 5.73597717285156250000e+00) (10, 1.12252960205078125000e+01) (11, 9.06126022338867187500e+00) (12, 5.71781301498413085938e+00) (13, 5.71245861053466796875e+00) (14, 1.51814231872558593750e+01) (15, 5.51036024093627929688e+00) (16, 5.65730094909667968750e+00) (17, 5.81794118881225585938e+00) (18, 5.77735376358032226562e+00) (19, 5.87879276275634765625e+00) 
