FANN_FLO_2.1
num_layers=3
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=3 17 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -2.80629944801330566406e+00) (1, 2.44271087646484375000e+00) (2, 9.85912799835205078125e-01) (0, -2.62295269966125488281e+00) (1, 2.65740704536437988281e+00) (2, 2.94784951210021972656e+00) (0, -2.70079326629638671875e+00) (1, 8.40533137321472167969e-01) (2, 1.91715610027313232422e+00) (0, -3.15229821205139160156e+00) (1, 6.22907131910324096680e-02) (2, 7.12883174419403076172e-01) (0, -1.66155850887298583984e+00) (1, 3.35520243644714355469e+00) (2, 9.68221187591552734375e-01) (0, -3.21477437019348144531e+00) (1, 4.63838398456573486328e-01) (2, 7.42977857589721679688e-01) (0, -1.78403007984161376953e+00) (1, 3.20756745338439941406e+00) (2, 1.05136215686798095703e+00) (0, -4.16367387771606445312e+00) (1, -1.86138439178466796875e+00) (2, 1.41357136890292167664e-02) (0, -1.77405953407287597656e+00) (1, 3.28469681739807128906e+00) (2, 9.51062917709350585938e-01) (0, -6.94433259963989257812e+00) (1, -8.26394796371459960938e-01) (2, 4.01260763406753540039e-01) (0, -2.29731321334838867188e+00) (1, -2.17516183853149414062e+00) (2, 1.17437839508056640625e+00) (0, -1.94216370582580566406e+00) (1, 1.88025116920471191406e+00) (2, 4.21857357025146484375e+00) (0, -1.44537162780761718750e+00) (1, -3.44312310218811035156e+00) (2, 8.30384850502014160156e-01) (0, -2.59033393859863281250e+00) (1, 7.08547115325927734375e-01) (2, 1.22633457183837890625e+00) (0, -2.97486615180969238281e+00) (1, 4.93318587541580200195e-01) (2, 8.75114262104034423828e-01) (0, -3.10097002983093261719e+00) (1, 1.66175341606140136719e+00) (2, 1.92492413520812988281e+00) (3, 1.51853489875793457031e+00) (4, -2.82749623060226440430e-01) (5, 1.01482458412647247314e-02) (6, 4.91256088018417358398e-01) (7, 5.40544629096984863281e-01) (8, 6.12728118896484375000e-01) (9, 5.66034793853759765625e-01) (10, 2.43797945976257324219e+00) (11, 5.25967419147491455078e-01) (12, 6.31663382053375244141e-01) (13, -4.30975735187530517578e-01) (14, 1.17443732917308807373e-01) (15, 2.51254796981811523438e+00) (16, 6.21198356151580810547e-01) (17, 6.26599669456481933594e-01) (18, 5.68868756294250488281e-01) (19, 9.66441705822944641113e-02) (3, 2.94804382324218750000e+00) (4, 1.31572544574737548828e+00) (5, 1.44262635707855224609e+00) (6, 1.64342021942138671875e+00) (7, 1.60538029670715332031e+00) (8, 1.66365635395050048828e+00) (9, 1.51326429843902587891e+00) (10, 2.61469388008117675781e+00) (11, 1.62853145599365234375e+00) (12, 1.81679284572601318359e+00) (13, 3.73390531539916992188e+00) (14, 1.28461694717407226562e+00) (15, 5.62151288986206054688e+00) (16, 1.60689365863800048828e+00) (17, 1.72088313102722167969e+00) (18, 1.36789309978485107422e+00) (19, 3.25943559408187866211e-01) (3, 5.45377731323242187500e+00) (4, 5.44294834136962890625e+00) (5, 5.36384582519531250000e+00) (6, 5.38204431533813476562e+00) (7, 5.40439844131469726562e+00) (8, 5.49658632278442382812e+00) (9, 5.42640447616577148438e+00) (10, 8.57087326049804687500e+00) (11, 5.44218540191650390625e+00) (12, 5.37257575988769531250e+00) (13, 1.08641672134399414062e+01) (14, 5.52693319320678710938e+00) (15, 1.99735298156738281250e+01) (16, 5.39738559722900390625e+00) (17, 5.39858293533325195312e+00) (18, 5.38870573043823242188e+00) (19, 4.61356163024902343750e+00) 
