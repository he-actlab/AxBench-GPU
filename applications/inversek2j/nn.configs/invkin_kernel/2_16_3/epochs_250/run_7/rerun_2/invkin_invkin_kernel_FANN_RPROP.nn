FANN_FLO_2.1
num_layers=3
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=3 17 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -3.48138117790222167969e+00) (1, 1.81539964675903320312e+00) (2, 1.97422170639038085938e+00) (0, -3.12934803962707519531e+00) (1, 7.50279068946838378906e-01) (2, 1.15210413932800292969e+00) (0, -2.26972484588623046875e+00) (1, 2.36812186241149902344e+00) (2, 3.83791065216064453125e+00) (0, -3.32357549667358398438e+00) (1, 2.01678133010864257812e+00) (2, 1.06339049339294433594e+00) (0, -2.39785981178283691406e+00) (1, -1.63467121124267578125e+00) (2, 2.93502950668334960938e+00) (0, -8.32577419281005859375e+00) (1, -7.11880159378051757812e+00) (2, 1.96433937549591064453e+00) (0, -3.21372604370117187500e+00) (1, 7.12681829929351806641e-01) (2, 1.08652603626251220703e+00) (0, -2.40288805961608886719e+00) (1, 3.55137372016906738281e+00) (2, -5.41383214294910430908e-02) (0, -3.15827798843383789062e+00) (1, 7.18035817146301269531e-01) (2, 1.06241428852081298828e+00) (0, -2.40211510658264160156e+00) (1, -4.53999900817871093750e+00) (2, 3.31182956695556640625e-01) (0, -2.47842860221862792969e+00) (1, 2.88985276222229003906e+00) (2, 2.02541708946228027344e+00) (0, -2.46073842048645019531e+00) (1, 2.71801400184631347656e+00) (2, 2.02714467048645019531e+00) (0, -5.91824817657470703125e+00) (1, -2.13697338104248046875e+00) (2, 8.79369378089904785156e-01) (0, -2.64326381683349609375e+00) (1, 3.50955939292907714844e+00) (2, 3.76344823837280273438e+00) (0, -2.63717269897460937500e+00) (1, 3.45373034477233886719e+00) (2, 3.62713289260864257812e+00) (0, -7.16392183303833007812e+00) (1, -4.06480021774768829346e-02) (2, 7.77289569377899169922e-01) (3, 1.61716759204864501953e-01) (4, 6.91011011600494384766e-01) (5, 3.50973516702651977539e-01) (6, 5.53777515888214111328e-01) (7, -1.63848066329956054688e+00) (8, 1.19872105121612548828e+00) (9, 7.88036108016967773438e-01) (10, 1.16305708885192871094e+00) (11, 7.82212495803833007812e-01) (12, 2.22884559631347656250e+00) (13, 3.78292143344879150391e-01) (14, 3.18169325590133666992e-01) (15, 2.18370032310485839844e+00) (16, 3.07274609804153442383e-01) (17, 3.85403841733932495117e-01) (18, 1.14926242828369140625e+00) (19, 1.15532845258712768555e-01) (3, 1.33544039726257324219e+00) (4, 1.66354298591613769531e+00) (5, 1.28482806682586669922e+00) (6, 1.56805276870727539062e+00) (7, 2.00812864303588867188e+00) (8, 2.93489575386047363281e+00) (9, 1.64582955837249755859e+00) (10, 3.00316977500915527344e+00) (11, 1.69914972782135009766e+00) (12, 6.13408374786376953125e+00) (13, 1.31348645687103271484e+00) (14, 1.27556383609771728516e+00) (15, 3.01700115203857421875e+00) (16, 1.27937662601470947266e+00) (17, 1.33233058452606201172e+00) (18, 1.83416581153869628906e+00) (19, 6.23217880725860595703e-01) (3, 5.27965927124023437500e+00) (4, 5.14540290832519531250e+00) (5, 5.10902261734008789062e+00) (6, 5.19063472747802734375e+00) (7, 9.55049419403076171875e+00) (8, 9.60646629333496093750e+00) (9, 5.21605920791625976562e+00) (10, 5.25167751312255859375e+00) (11, 5.16125774383544921875e+00) (12, 1.93280506134033203125e+01) (13, 5.16646337509155273438e+00) (14, 5.16816997528076171875e+00) (15, 7.74761819839477539062e+00) (16, 5.16716623306274414062e+00) (17, 5.14498233795166015625e+00) (18, 5.10566902160644531250e+00) (19, 5.12739610671997070312e+00) 
