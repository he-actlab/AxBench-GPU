FANN_FLO_2.1
num_layers=3
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=3 17 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -3.85645341873168945312e+00) (1, -2.43516850471496582031e+00) (2, 4.54779803752899169922e-01) (0, -3.31371808052062988281e+00) (1, 2.17343783378601074219e+00) (2, 8.76405179500579833984e-01) (0, -3.12082600593566894531e+00) (1, 3.62968659400939941406e+00) (2, 3.78537130355834960938e+00) (0, -2.92823052406311035156e+00) (1, 3.30646777153015136719e+00) (2, 4.05165910720825195312e+00) (0, -6.89538621902465820312e+00) (1, 1.92870986461639404297e+00) (2, 8.20417344570159912109e-01) (0, -3.14614486694335937500e+00) (1, 3.65460872650146484375e+00) (2, 4.02074241638183593750e+00) (0, -2.97526240348815917969e+00) (1, -2.90935873985290527344e+00) (2, 5.48441827297210693359e-01) (0, -7.30823516845703125000e+00) (1, 1.96548855304718017578e+00) (2, 4.29611492156982421875e+00) (0, -2.77156543731689453125e+00) (1, 3.83908033370971679688e+00) (2, 1.39119729399681091309e-01) (0, -9.27072048187255859375e+00) (1, 1.22016239166259765625e+00) (2, -2.54906088113784790039e-01) (0, -2.25600266456604003906e+00) (1, -1.32065272331237792969e+00) (2, 1.04631912708282470703e+00) (0, -1.65709614753723144531e+00) (1, 3.58583354949951171875e+00) (2, 5.05207479000091552734e-01) (0, -1.89059650897979736328e+00) (1, -4.66627931594848632812e+00) (2, 9.45150375366210937500e-01) (0, -1.02407751083374023438e+01) (1, -1.19714009761810302734e+00) (2, -1.03060328960418701172e+00) (0, -1.64474129676818847656e+00) (1, -1.48476159572601318359e+00) (2, 2.97739028930664062500e+00) (0, -5.94614410400390625000e+00) (1, 3.14787983894348144531e+00) (2, 4.59703540802001953125e+00) (3, 1.12908291816711425781e+00) (4, 9.60840344429016113281e-01) (5, 2.73736149072647094727e-01) (6, 2.47865423560142517090e-01) (7, 1.20914828777313232422e+00) (8, 2.83796638250350952148e-01) (9, 1.11351728439331054688e+00) (10, 1.78117468953132629395e-01) (11, 9.22487795352935791016e-01) (12, 8.63213002681732177734e-01) (13, 3.23700666427612304688e-01) (14, 1.04153466224670410156e+00) (15, 1.73867571353912353516e+00) (16, 1.37102258205413818359e+00) (17, -9.84123885631561279297e-01) (18, 1.56721681356430053711e-01) (19, 2.89645999670028686523e-01) (3, 2.40521621704101562500e+00) (4, 1.27910768985748291016e+00) (5, 1.60772573947906494141e+00) (6, 1.52906680107116699219e+00) (7, 2.41889691352844238281e+00) (8, 1.61616694927215576172e+00) (9, 2.41205430030822753906e+00) (10, 1.98007237911224365234e+00) (11, 2.62291240692138671875e+00) (12, 2.05289769172668457031e+00) (13, 1.95818614959716796875e+00) (14, 1.36541152000427246094e+00) (15, 5.13723134994506835938e+00) (16, 2.31479144096374511719e+00) (17, 5.09317874908447265625e-01) (18, 1.98065257072448730469e+00) (19, 9.11927938461303710938e-01) (3, 6.96406459808349609375e+00) (4, 6.13051271438598632812e+00) (5, 5.80035352706909179688e+00) (6, 5.91304063796997070312e+00) (7, 6.34613752365112304688e+00) (8, 5.78593587875366210938e+00) (9, 6.49093675613403320312e+00) (10, 5.93606996536254882812e+00) (11, 5.08784341812133789062e+00) (12, 6.34014940261840820312e+00) (13, 6.30121374130249023438e+00) (14, 5.73210287094116210938e+00) (15, 1.73248863220214843750e+01) (16, 6.28961753845214843750e+00) (17, 6.24354743957519531250e+00) (18, 5.89549493789672851562e+00) (19, 5.77917957305908203125e+00) 
