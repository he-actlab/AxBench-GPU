FANN_FLO_2.1
num_layers=3
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=3 17 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -3.32154178619384765625e+00) (1, 3.51949357986450195312e+00) (2, 1.44102549552917480469e+00) (0, -5.42833995819091796875e+00) (1, 1.66565108299255371094e+00) (2, 2.29302597045898437500e+00) (0, -1.39836585521697998047e+00) (1, -9.51421380043029785156e-01) (2, 1.31202673912048339844e+00) (0, -4.51963376998901367188e+00) (1, 2.20733809471130371094e+00) (2, 8.35163712501525878906e-01) (0, -1.05162787437438964844e+00) (1, -8.90116095542907714844e-01) (2, 1.44455420970916748047e+00) (0, -1.34781098365783691406e+00) (1, -3.33946084976196289062e+00) (2, 7.95618116855621337891e-01) (0, -3.35261154174804687500e+00) (1, 4.35965871810913085938e+00) (2, 4.32248544692993164062e+00) (0, -4.97422266006469726562e+00) (1, -3.07472300529479980469e+00) (2, -3.79145801067352294922e-01) (0, -9.82787704467773437500e+00) (1, 2.18185424804687500000e+00) (2, -7.99468994140625000000e-01) (0, -3.79341506958007812500e+00) (1, 3.20420217514038085938e+00) (2, 1.65583276748657226562e+00) (0, -3.35538125038146972656e+00) (1, 4.36806821823120117188e+00) (2, 4.38317155838012695312e+00) (0, -1.74071657657623291016e+00) (1, -8.95361721515655517578e-01) (2, 8.26698780059814453125e-01) (0, -3.91999125480651855469e+00) (1, 2.70924448966979980469e+00) (2, 1.28095436096191406250e+00) (0, -7.27151775360107421875e+00) (1, -1.24092793464660644531e+00) (2, 5.10004581883549690247e-03) (0, -2.69584918022155761719e+00) (1, 5.71895551681518554688e+00) (2, 7.11933569982647895813e-03) (0, -3.24385237693786621094e+00) (1, 3.99859452247619628906e+00) (2, 4.44256210327148437500e+00) (3, 1.58072799444198608398e-01) (4, 4.08097267150878906250e-01) (5, -2.66270071268081665039e-01) (6, 6.86078071594238281250e-01) (7, -1.66673302650451660156e+00) (8, 2.27956438064575195312e+00) (9, 2.78503447771072387695e-01) (10, 2.03776693344116210938e+00) (11, 1.57049000263214111328e+00) (12, 4.48501050472259521484e-01) (13, 3.91447275876998901367e-01) (14, 7.71023869514465332031e-01) (15, 8.28418493270874023438e-01) (16, 1.39088273048400878906e+00) (17, 9.47881162166595458984e-01) (18, 3.30650061368942260742e-01) (19, 5.14447808265686035156e-01) (3, 1.34881198406219482422e+00) (4, 1.87854766845703125000e+00) (5, 1.76537084579467773438e+00) (6, 1.65135538578033447266e+00) (7, -3.16130071878433227539e-01) (8, 6.67008495330810546875e+00) (9, 1.22253561019897460938e+00) (10, 3.04900503158569335938e+00) (11, 2.89139509201049804688e+00) (12, 1.77178275585174560547e+00) (13, 1.23982262611389160156e+00) (14, 2.13865947723388671875e+00) (15, 1.84531366825103759766e+00) (16, 2.59963917732238769531e+00) (17, 2.54505705833435058594e+00) (18, 1.23827552795410156250e+00) (19, 1.04514193534851074219e+00) (3, 5.49761772155761718750e+00) (4, 5.45153951644897460938e+00) (5, 5.39314937591552734375e+00) (6, 5.35696649551391601562e+00) (7, 5.47124862670898437500e+00) (8, 2.19237232208251953125e+01) (9, 5.33583593368530273438e+00) (10, 8.06667613983154296875e+00) (11, 8.69386672973632812500e+00) (12, 5.33302021026611328125e+00) (13, 5.32430696487426757812e+00) (14, 5.70918560028076171875e+00) (15, 5.40569067001342773438e+00) (16, 7.35058879852294921875e+00) (17, 5.52725601196289062500e+00) (18, 5.34591531753540039062e+00) (19, 5.33459758758544921875e+00) 
