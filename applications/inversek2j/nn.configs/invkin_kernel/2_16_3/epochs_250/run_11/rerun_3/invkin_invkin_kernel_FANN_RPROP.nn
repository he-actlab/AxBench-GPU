FANN_FLO_2.1
num_layers=3
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=3 17 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.90712285041809082031e+00) (1, -2.30326271057128906250e+00) (2, 4.82413142919540405273e-01) (0, -5.25180625915527343750e+00) (1, -1.01290071010589599609e+00) (2, 5.90626120567321777344e-01) (0, -2.62837886810302734375e+00) (1, 8.46075117588043212891e-02) (2, 5.98473358154296875000e+00) (0, -3.41287088394165039062e+00) (1, 2.00860786437988281250e+00) (2, 9.07434880733489990234e-01) (0, -1.98307871818542480469e+00) (1, -2.65898728370666503906e+00) (2, 4.20337170362472534180e-01) (0, -3.37253832817077636719e+00) (1, 2.04130339622497558594e+00) (2, 8.90945672988891601562e-01) (0, -2.33960032463073730469e+00) (1, 4.00349187850952148438e+00) (2, 6.56669437885284423828e-02) (0, -3.99329686164855957031e+00) (1, 4.51305896043777465820e-01) (2, 1.49853336811065673828e+00) (0, -1.31986141204833984375e+00) (1, -4.20122528076171875000e+00) (2, 1.31293058395385742188e-01) (0, -5.16839313507080078125e+00) (1, 5.22257626056671142578e-01) (2, 1.68722546100616455078e+00) (0, -4.04143333435058593750e+00) (1, 3.77945661544799804688e+00) (2, 5.16390657424926757812e+00) (0, -4.00690364837646484375e+00) (1, 3.84238576889038085938e+00) (2, 4.99336099624633789062e+00) (0, -4.93300867080688476562e+00) (1, -2.88911628723144531250e+00) (2, 4.35255527496337890625e-01) (0, -3.40512800216674804688e+00) (1, 2.12660050392150878906e+00) (2, 8.26985597610473632812e-01) (0, -3.25401997566223144531e+00) (1, -1.41605126857757568359e+00) (2, 4.71270751953125000000e+00) (0, -2.45209813117980957031e+00) (1, 4.03763341903686523438e+00) (2, -6.55443593859672546387e-02) (3, 6.19210183620452880859e-01) (4, 1.88038218021392822266e+00) (5, 2.44866341352462768555e-01) (6, 6.40225112438201904297e-01) (7, 8.44462454319000244141e-01) (8, 6.03089392185211181641e-01) (9, 7.18960165977478027344e-01) (10, 7.66984045505523681641e-01) (11, 1.95110476016998291016e+00) (12, 1.14847135543823242188e+00) (13, 3.30157130956649780273e-01) (14, 2.92383044958114624023e-01) (15, 1.24869585037231445312e+00) (16, 7.14952170848846435547e-01) (17, -1.38115286827087402344e+00) (18, 7.37696290016174316406e-01) (19, 4.71185177564620971680e-01) (3, 2.40012741088867187500e+00) (4, 3.67749929428100585938e+00) (5, 1.41630125045776367188e+00) (6, 1.46594214439392089844e+00) (7, 2.93692612648010253906e+00) (8, 1.53971290588378906250e+00) (9, 2.39785218238830566406e+00) (10, 1.89606642723083496094e+00) (11, 4.35480165481567382812e+00) (12, 1.86896717548370361328e+00) (13, 1.33323180675506591797e+00) (14, 1.36859142780303955078e+00) (15, 2.83565878868103027344e+00) (16, 1.44800233840942382812e+00) (17, 8.97696793079376220703e-01) (18, 2.39227843284606933594e+00) (19, 1.27146208286285400391e+00) (3, 9.34020996093750000000e+00) (4, 1.21453485488891601562e+01) (5, 6.63994455337524414062e+00) (6, 5.02665328979492187500e+00) (7, 8.83781814575195312500e+00) (8, 5.04607152938842773438e+00) (9, 5.00789022445678710938e+00) (10, 5.03860902786254882812e+00) (11, 1.35343103408813476562e+01) (12, 5.03992843627929687500e+00) (13, 6.67905521392822265625e+00) (14, 6.71062278747558593750e+00) (15, 7.84875059127807617188e+00) (16, 5.02008008956909179688e+00) (17, 4.94521999359130859375e+00) (18, 4.99789905548095703125e+00) (19, 6.68961572647094726562e+00) 
