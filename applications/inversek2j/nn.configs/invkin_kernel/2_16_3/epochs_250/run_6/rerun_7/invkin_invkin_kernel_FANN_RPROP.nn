FANN_FLO_2.1
num_layers=3
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=3 17 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -3.97785496711730957031e+00) (1, -2.32290720939636230469e+00) (2, 6.01488053798675537109e-01) (0, -3.79905605316162109375e+00) (1, 3.98107618093490600586e-01) (2, 1.12974858283996582031e+00) (0, -1.42517805099487304688e+00) (1, 4.03253841400146484375e+00) (2, -3.70391160249710083008e-01) (0, -2.58676719665527343750e+00) (1, 3.95586133003234863281e+00) (2, 3.27301001548767089844e+00) (0, -1.92309772968292236328e+00) (1, -4.79448223114013671875e+00) (2, 9.53538119792938232422e-01) (0, -3.39259552955627441406e+00) (1, 1.71064436435699462891e+00) (2, 1.36261534690856933594e+00) (0, -1.45993983745574951172e+00) (1, -1.86898064613342285156e+00) (2, 1.59345161914825439453e+00) (0, -3.62601590156555175781e+00) (1, -4.33049011230468750000e+00) (2, 1.11467587947845458984e+00) (0, -3.12293219566345214844e+00) (1, 2.25386714935302734375e+00) (2, 1.70003974437713623047e+00) (0, -3.32685375213623046875e+00) (1, 4.00092935562133789062e+00) (2, 2.93031144142150878906e+00) (0, -5.23632955551147460938e+00) (1, -5.62228560447692871094e-01) (2, 6.76008224487304687500e-01) (0, -1.34743297100067138672e+00) (1, -7.00400471687316894531e-01) (2, 5.14448547363281250000e+00) (0, -3.40794062614440917969e+00) (1, -1.28143358230590820312e+00) (2, 7.86086082458496093750e-01) (0, -8.11979472637176513672e-01) (1, -7.43192815780639648438e+00) (2, 9.25040125846862792969e-01) (0, -3.50233507156372070312e+00) (1, 9.55473303794860839844e-01) (2, 2.09641456604003906250e+00) (0, -2.80366635322570800781e+00) (1, 2.74949598312377929688e+00) (2, 1.51134729385375976562e+00) (3, 1.93058359622955322266e+00) (4, 7.81471908092498779297e-01) (5, 6.37492179870605468750e-01) (6, 4.00263011455535888672e-01) (7, 1.40686619281768798828e+00) (8, 8.49604547023773193359e-01) (9, -2.75352191925048828125e+00) (10, 2.24398517608642578125e+00) (11, 6.43046021461486816406e-01) (12, 4.84225213527679443359e-01) (13, 1.56685316562652587891e+00) (14, 1.62230983376502990723e-01) (15, 7.99036026000976562500e-01) (16, 5.72323024272918701172e-01) (17, 7.47999787330627441406e-01) (18, 6.36790394783020019531e-01) (19, 2.51581072807312011719e-01) (3, 2.81823015213012695312e+00) (4, 3.28990626335144042969e+00) (5, 1.74011790752410888672e+00) (6, 1.57481741905212402344e+00) (7, 3.54270601272583007812e+00) (8, 2.19347167015075683594e+00) (9, 5.16593813896179199219e-01) (10, 2.86626029014587402344e+00) (11, 1.93343985080718994141e+00) (12, 1.58316040039062500000e+00) (13, 2.67863869667053222656e+00) (14, 1.15615546703338623047e+00) (15, 1.86335146427154541016e+00) (16, 2.88286542892456054688e+00) (17, 2.05586862564086914062e+00) (18, 2.15507459640502929688e+00) (19, 1.10857701301574707031e+00) (3, 7.01466417312622070312e+00) (4, 1.19044322967529296875e+01) (5, 5.83886289596557617188e+00) (6, 5.84546470642089843750e+00) (7, 1.10190954208374023438e+01) (8, 6.18167114257812500000e+00) (9, 7.05957174301147460938e+00) (10, 6.96763706207275390625e+00) (11, 6.23761510848999023438e+00) (12, 5.83529090881347656250e+00) (13, 6.48939561843872070312e+00) (14, 5.82937526702880859375e+00) (15, 6.54770135879516601562e+00) (16, 1.08675079345703125000e+01) (17, 6.11402893066406250000e+00) (18, 6.19605875015258789062e+00) (19, 5.69916963577270507812e+00) 
