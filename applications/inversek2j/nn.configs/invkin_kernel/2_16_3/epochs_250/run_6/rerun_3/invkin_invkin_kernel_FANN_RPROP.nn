FANN_FLO_2.1
num_layers=3
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=3 17 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.19764697551727294922e+00) (1, 1.52163314819335937500e+00) (2, 2.53089427947998046875e+00) (0, -2.53397464752197265625e+00) (1, 3.61580324172973632812e+00) (2, 1.99195969104766845703e+00) (0, -3.90223765373229980469e+00) (1, 1.87187886238098144531e+00) (2, 2.48246788978576660156e+00) (0, -2.79446864128112792969e+00) (1, 3.35092663764953613281e+00) (2, 2.69883704185485839844e+00) (0, -3.15882635116577148438e+00) (1, -5.46667957305908203125e+00) (2, 1.33765351772308349609e+00) (0, -3.65071654319763183594e+00) (1, -3.33224654197692871094e+00) (2, 8.49830567836761474609e-01) (0, -1.83577179908752441406e+00) (1, -7.66275691986083984375e+00) (2, 1.64523911476135253906e+00) (0, -6.42172861099243164062e+00) (1, -3.69990080595016479492e-01) (2, 1.20693087577819824219e+00) (0, -1.72038400173187255859e+00) (1, 2.92151999473571777344e+00) (2, 2.52799950540065765381e-02) (0, -4.34373998641967773438e+00) (1, 1.12984275817871093750e+00) (2, 2.50278949737548828125e+00) (0, -4.11301708221435546875e+00) (1, 2.54599523544311523438e+00) (2, 2.77892518043518066406e+00) (0, -3.48643922805786132812e+00) (1, 4.63972747325897216797e-01) (2, 1.26227271556854248047e+00) (0, -3.48142981529235839844e+00) (1, 5.53110837936401367188e-01) (2, 1.19063222408294677734e+00) (0, -1.45506477355957031250e+00) (1, 1.27719211578369140625e+00) (2, 2.44594383239746093750e+00) (0, -4.22534990310668945312e+00) (1, -1.48933768272399902344e+00) (2, 4.92647588253021240234e-01) (0, -1.72892498970031738281e+00) (1, -2.00966501235961914062e+00) (2, 2.00598597526550292969e+00) (3, 4.03726011514663696289e-01) (4, 4.78072136640548706055e-01) (5, 4.87322390079498291016e-01) (6, 4.60388958454132080078e-01) (7, 7.66058743000030517578e-01) (8, 2.67726612091064453125e+00) (9, 1.22993397712707519531e+00) (10, 9.57858622074127197266e-01) (11, 9.11727011203765869141e-01) (12, 4.73548412322998046875e-01) (13, 5.66860496997833251953e-01) (14, 7.46045827865600585938e-01) (15, 7.64105796813964843750e-01) (16, 3.92574667930603027344e-01) (17, 2.28704476356506347656e+00) (18, -2.41963863372802734375e+00) (19, 5.26391938328742980957e-02) (3, 1.03801059722900390625e+00) (4, 1.34109306335449218750e+00) (5, 1.55074942111968994141e+00) (6, 1.27088713645935058594e+00) (7, 2.81426668167114257812e+00) (8, 2.57243251800537109375e+00) (9, 2.98338341712951660156e+00) (10, 2.01723480224609375000e+00) (11, 3.05221581459045410156e+00) (12, 1.50520932674407958984e+00) (13, 1.42482614517211914062e+00) (14, 2.01568293571472167969e+00) (15, 2.27381491661071777344e+00) (16, 2.24645042419433593750e+00) (17, 3.85747528076171875000e+00) (18, 1.44356381893157958984e+00) (19, 8.07059645652770996094e-01) (3, 5.97444105148315429688e+00) (4, 5.26806688308715820312e+00) (5, 5.33761215209960937500e+00) (6, 5.32625102996826171875e+00) (7, 8.06225585937500000000e+00) (8, 7.82599020004272460938e+00) (9, 9.94606876373291015625e+00) (10, 6.42831373214721679688e+00) (11, 5.90039396286010742188e+00) (12, 5.21345472335815429688e+00) (13, 5.33216714859008789062e+00) (14, 6.38808536529541015625e+00) (15, 6.43838071823120117188e+00) (16, 6.40318202972412109375e+00) (17, 1.06074104309082031250e+01) (18, 7.80655479431152343750e+00) (19, 6.38200378417968750000e+00) 
