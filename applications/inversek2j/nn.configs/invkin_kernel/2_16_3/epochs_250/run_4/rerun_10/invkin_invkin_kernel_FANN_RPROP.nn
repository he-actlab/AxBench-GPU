FANN_FLO_2.1
num_layers=3
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=3 17 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -2.13020300865173339844e+00) (1, 2.21227717399597167969e+00) (2, 1.81733155250549316406e+00) (0, -2.66965460777282714844e+00) (1, 1.20551645755767822266e+00) (2, 2.03034400939941406250e+00) (0, -2.07463240623474121094e+00) (1, 1.52617251873016357422e+00) (2, 1.84672188758850097656e+00) (0, -1.93292498588562011719e+00) (1, 6.08386468887329101562e+00) (2, 4.21786010265350341797e-02) (0, -1.38275349140167236328e+00) (1, -8.58914732933044433594e-01) (2, 1.00407516956329345703e+00) (0, -7.73651313781738281250e+00) (1, 1.02492535114288330078e+00) (2, 1.43130242824554443359e-01) (0, -2.64025521278381347656e+00) (1, 2.47427201271057128906e+00) (2, 1.24714016914367675781e+00) (0, -3.13168454170227050781e+00) (1, 1.13521945476531982422e+00) (2, 1.99613833427429199219e+00) (0, -1.99400067329406738281e+00) (1, 3.34472250938415527344e+00) (2, 4.44487869739532470703e-01) (0, -2.84788393974304199219e+00) (1, -3.75692653656005859375e+00) (2, 9.68173682689666748047e-01) (0, -1.75734984874725341797e+00) (1, -6.77298498153686523438e+00) (2, 1.70084214210510253906e+00) (0, -3.85737419128417968750e-01) (1, -1.13331937789916992188e+00) (2, -4.24455851316452026367e-02) (0, -4.28099250793457031250e+00) (1, -9.15765523910522460938e-01) (2, 5.52870512008666992188e-01) (0, -2.17923617362976074219e+00) (1, 6.43873643875122070312e+00) (2, 6.39399707317352294922e-01) (0, -5.69500017166137695312e+00) (1, -3.50637388229370117188e+00) (2, 5.63938796520233154297e-01) (0, -4.18108606338500976562e+00) (1, 1.45736420154571533203e+00) (2, 9.23554956912994384766e-01) (3, 4.46707904338836669922e-01) (4, 4.20438826084136962891e-01) (5, 4.13523405790328979492e-01) (6, 7.60265290737152099609e-01) (7, -2.97345697879791259766e-01) (8, 9.64805781841278076172e-01) (9, 4.24543112516403198242e-01) (10, 3.12733650207519531250e-01) (11, 5.27443230152130126953e-01) (12, 2.30467748641967773438e+00) (13, 1.84355926513671875000e+00) (14, -3.31641125679016113281e+00) (15, 1.62350034713745117188e+00) (16, 3.21417361497879028320e-01) (17, 1.30756521224975585938e+00) (18, 1.16888451576232910156e+00) (19, 4.79507774114608764648e-01) (3, 1.55080854892730712891e+00) (4, 1.56677842140197753906e+00) (5, 1.58157610893249511719e+00) (6, 1.96520078182220458984e+00) (7, 3.24676418304443359375e+00) (8, 1.82638716697692871094e+00) (9, 1.68538153171539306641e+00) (10, 1.55125081539154052734e+00) (11, 1.55573010444641113281e+00) (12, 4.05630302429199218750e+00) (13, 3.56991028785705566406e+00) (14, -5.36990642547607421875e-01) (15, 3.32058787345886230469e+00) (16, 1.38512563705444335938e+00) (17, 1.94005870819091796875e+00) (18, 2.95926308631896972656e+00) (19, 8.33394944667816162109e-01) (3, 5.37608623504638671875e+00) (4, 5.25389575958251953125e+00) (5, 5.20851325988769531250e+00) (6, 5.51047897338867187500e+00) (7, 1.07295808792114257812e+01) (8, 5.16477918624877929688e+00) (9, 5.26243209838867187500e+00) (10, 5.22029590606689453125e+00) (11, 5.47917604446411132812e+00) (12, 1.01176195144653320312e+01) (13, 9.23434257507324218750e+00) (14, 1.06962594985961914062e+01) (15, 1.06883649826049804688e+01) (16, 5.50979900360107421875e+00) (17, 5.35435867309570312500e+00) (18, 9.35175132751464843750e+00) (19, 5.22460412979125976562e+00) 
