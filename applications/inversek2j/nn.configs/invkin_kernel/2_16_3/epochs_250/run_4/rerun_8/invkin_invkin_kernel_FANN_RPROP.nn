FANN_FLO_2.1
num_layers=3
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=3 17 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -2.99091219902038574219e+00) (1, -2.38336634635925292969e+00) (2, 8.75823199748992919922e-01) (0, -3.52601671218872070312e+00) (1, 2.02744936943054199219e+00) (2, 1.19236171245574951172e+00) (0, -2.41159939765930175781e+00) (1, 3.77704977989196777344e+00) (2, 2.62012720108032226562e+00) (0, -1.81654655933380126953e+00) (1, -5.20433950424194335938e+00) (2, 7.52970159053802490234e-01) (0, -2.00773715972900390625e+00) (1, 2.17060375213623046875e+00) (2, 1.25650441646575927734e+00) (0, -1.66507148742675781250e+00) (1, 3.48875355720520019531e+00) (2, 8.68574798107147216797e-01) (0, -2.78441476821899414062e+00) (1, 5.64202368259429931641e-01) (2, 1.50290071964263916016e+00) (0, -5.74290370941162109375e+00) (1, -1.77883303165435791016e+00) (2, 6.38807475566864013672e-01) (0, -2.30632853507995605469e+00) (1, -1.02680289745330810547e+00) (2, 3.19061207771301269531e+00) (0, -2.98342800140380859375e+00) (1, 4.33133602142333984375e-01) (2, 1.50567054748535156250e+00) (0, -2.36891746520996093750e+00) (1, 1.76149916648864746094e+00) (2, 1.37301027774810791016e+00) (0, -2.82019472122192382812e+00) (1, 5.68839311599731445312e-01) (2, 1.49945771694183349609e+00) (0, -1.91907787322998046875e+00) (1, 2.19947576522827148438e+00) (2, 1.41265439987182617188e+00) (0, -2.56323266029357910156e+00) (1, -3.08026123046875000000e+00) (2, 9.97918426990509033203e-01) (0, -1.91909074783325195312e+00) (1, 2.15301918983459472656e+00) (2, 1.38340401649475097656e+00) (0, -8.71907997131347656250e+00) (1, 4.99075204133987426758e-01) (2, 7.84324824810028076172e-01) (3, 8.90363991260528564453e-01) (4, 1.14911746978759765625e+00) (5, 1.26413360238075256348e-01) (6, 2.08317852020263671875e+00) (7, 6.15523338317871093750e-01) (8, 8.52204203605651855469e-01) (9, 6.11233413219451904297e-01) (10, 1.97209465503692626953e+00) (11, -1.82920992374420166016e+00) (12, 5.23079037666320800781e-01) (13, 5.56077480316162109375e-01) (14, 5.27445256710052490234e-01) (15, 4.77261811494827270508e-01) (16, 7.83460676670074462891e-01) (17, 5.16649186611175537109e-01) (18, 1.41735231876373291016e+00) (19, 1.39039516448974609375e-01) (3, 2.91385865211486816406e+00) (4, 1.65656268596649169922e+00) (5, 1.31983792781829833984e+00) (6, 4.60750198364257812500e+00) (7, 1.72695147991180419922e+00) (8, 1.62732303142547607422e+00) (9, 1.62151861190795898438e+00) (10, 3.30524396896362304688e+00) (11, 5.96046745777130126953e-01) (12, 1.57263970375061035156e+00) (13, 1.76862311363220214844e+00) (14, 1.71944701671600341797e+00) (15, 1.80860900878906250000e+00) (16, 3.15661573410034179688e+00) (17, 1.81802606582641601562e+00) (18, 2.01966166496276855469e+00) (19, 1.18530535697937011719e+00) (3, 9.62489891052246093750e+00) (4, 5.00699329376220703125e+00) (5, 6.80647516250610351562e+00) (6, 1.58499422073364257812e+01) (7, 4.96277046203613281250e+00) (8, 6.72043085098266601562e+00) (9, 5.16312551498413085938e+00) (10, 9.86398410797119140625e+00) (11, 5.19380044937133789062e+00) (12, 5.22410917282104492188e+00) (13, 4.99668693542480468750e+00) (14, 5.08307695388793945312e+00) (15, 5.04348707199096679688e+00) (16, 9.51205158233642578125e+00) (17, 4.95890378952026367188e+00) (18, 5.18982219696044921875e+00) (19, 6.66580867767333984375e+00) 
