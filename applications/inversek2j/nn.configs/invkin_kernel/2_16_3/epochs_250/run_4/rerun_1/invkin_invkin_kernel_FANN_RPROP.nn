FANN_FLO_2.1
num_layers=3
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=3 17 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -2.60031199455261230469e+00) (1, 3.60251992940902709961e-01) (2, 1.48344469070434570312e+00) (0, -3.07886266708374023438e+00) (1, 2.16764354705810546875e+00) (2, 1.94142711162567138672e+00) (0, -6.52226686477661132812e+00) (1, -1.76647913455963134766e+00) (2, -7.04185217618942260742e-02) (0, -5.66872119903564453125e+00) (1, 3.28457534313201904297e-01) (2, 2.31377318501472473145e-01) (0, -5.00555944442749023438e+00) (1, 1.90947937965393066406e+00) (2, 7.01674938201904296875e-01) (0, -2.53846836090087890625e+00) (1, 2.15039181709289550781e+00) (2, 2.00667786598205566406e+00) (0, -2.16547203063964843750e+00) (1, 4.14563655853271484375e+00) (2, 1.33250188827514648438e+00) (0, -3.42965888977050781250e+00) (1, -3.59780430793762207031e+00) (2, 6.85539662837982177734e-01) (0, -2.12042236328125000000e+00) (1, 4.27562856674194335938e+00) (2, 1.20702540874481201172e+00) (0, -2.62306642532348632812e+00) (1, 2.16252827644348144531e+00) (2, 1.91528463363647460938e+00) (0, -3.18142127990722656250e+00) (1, -1.85178363323211669922e+00) (2, 6.64716422557830810547e-01) (0, -1.97933685779571533203e+00) (1, 3.88589739799499511719e+00) (2, 1.44515347480773925781e+00) (0, -8.16799581050872802734e-01) (1, -1.06669330596923828125e+00) (2, 9.48661208152770996094e-01) (0, -3.80247950553894042969e+00) (1, 1.90097188949584960938e+00) (2, 1.25950169563293457031e+00) (0, -2.07122230529785156250e+00) (1, -6.80465412139892578125e+00) (2, 1.65259850025177001953e+00) (0, -1.17885708808898925781e+00) (1, -1.66914284229278564453e+00) (2, 7.15658366680145263672e-01) (3, 5.84025442600250244141e-01) (4, 5.37670195102691650391e-01) (5, 1.10988235473632812500e+00) (6, 1.51156032085418701172e+00) (7, 8.70659530162811279297e-01) (8, 5.54176151752471923828e-01) (9, 3.88319969177246093750e-01) (10, 2.50378537178039550781e+00) (11, 4.33094739913940429688e-01) (12, 5.11487483978271484375e-01) (13, 1.15303695201873779297e+00) (14, 6.51739537715911865234e-01) (15, -2.80140590667724609375e+00) (16, 5.04454970359802246094e-01) (17, 1.50692403316497802734e+00) (18, 2.12526395916938781738e-01) (19, 5.38911342620849609375e-01) (3, 1.93937337398529052734e+00) (4, 1.73892140388488769531e+00) (5, 2.16467332839965820312e+00) (6, 3.26610302925109863281e+00) (7, 1.88402473926544189453e+00) (8, 1.83477878570556640625e+00) (9, 1.45390331745147705078e+00) (10, 3.02486729621887207031e+00) (11, 2.03004717826843261719e+00) (12, 1.84736990928649902344e+00) (13, 2.12238788604736328125e+00) (14, 1.64841139316558837891e+00) (15, 8.47420811653137207031e-01) (16, 1.94835901260375976562e+00) (17, 3.45238280296325683594e+00) (18, 2.03999114036560058594e+00) (19, 9.47357952594757080078e-01) (3, 5.98869562149047851562e+00) (4, 5.85294771194458007812e+00) (5, 6.05268478393554687500e+00) (6, 1.03004875183105468750e+01) (7, 5.87968063354492187500e+00) (8, 5.91522407531738281250e+00) (9, 5.93368053436279296875e+00) (10, 6.03498363494873046875e+00) (11, 5.94075918197631835938e+00) (12, 5.78593730926513671875e+00) (13, 5.97365999221801757812e+00) (14, 5.86204624176025390625e+00) (15, 8.84591197967529296875e+00) (16, 5.84786701202392578125e+00) (17, 1.04781980514526367188e+01) (18, 8.93107891082763671875e+00) (19, 5.87965536117553710938e+00) 
