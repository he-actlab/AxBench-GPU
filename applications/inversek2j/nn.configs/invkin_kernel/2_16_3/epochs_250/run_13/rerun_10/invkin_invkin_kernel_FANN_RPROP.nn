FANN_FLO_2.1
num_layers=3
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=3 17 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -5.17874336242675781250e+00) (1, 6.99975907802581787109e-01) (2, 7.03276753425598144531e-01) (0, -2.57631492614746093750e+00) (1, -1.49663639068603515625e+00) (2, 1.08182513713836669922e+00) (0, -2.17454695701599121094e+00) (1, 3.43292140960693359375e+00) (2, 1.69696319103240966797e+00) (0, -3.40377879142761230469e+00) (1, 1.24808907508850097656e+00) (2, 1.80310893058776855469e+00) (0, -1.29375302791595458984e+00) (1, -4.47727012634277343750e+00) (2, 6.89988806843757629395e-02) (0, -1.90844333171844482422e+00) (1, 3.28397917747497558594e+00) (2, 1.49408626556396484375e+00) (0, -3.55303978919982910156e+00) (1, 1.25742411613464355469e+00) (2, 1.67171633243560791016e+00) (0, -1.03656852245330810547e+00) (1, -2.27432155609130859375e+00) (2, 5.48384010791778564453e-01) (0, -2.21748256683349609375e+00) (1, 5.59004402160644531250e+00) (2, 1.30483710765838623047e+00) (0, -2.83447909355163574219e+00) (1, 5.31644487380981445312e+00) (2, -8.79799425601959228516e-01) (0, -5.03260326385498046875e+00) (1, 7.90271580219268798828e-01) (2, 7.58076965808868408203e-01) (0, -3.29472571611404418945e-01) (1, -1.40180230140686035156e+00) (2, 9.46351051330566406250e-01) (0, -6.20728874206542968750e+00) (1, -5.22064304351806640625e+00) (2, 1.15185841917991638184e-01) (0, -3.12690925598144531250e+00) (1, 1.84251737594604492188e+00) (2, 1.76199817657470703125e+00) (0, -6.17728471755981445312e+00) (1, -1.17166519165039062500e+00) (2, -3.47889542579650878906e-01) (0, -3.01784300804138183594e+00) (1, 1.95491504669189453125e+00) (2, 1.80190110206604003906e+00) (3, 7.81100392341613769531e-01) (4, 3.41721594333648681641e-01) (5, 4.04497087001800537109e-01) (6, 5.11363446712493896484e-01) (7, 2.83716678619384765625e+00) (8, 4.30027335882186889648e-01) (9, 4.73791807889938354492e-01) (10, 6.16381645202636718750e-01) (11, 4.16615903377532958984e-01) (12, 8.54902207851409912109e-01) (13, 8.20194184780120849609e-01) (14, -1.43543767929077148438e+00) (15, 1.80722332000732421875e+00) (16, 4.49480772018432617188e-01) (17, 1.67122173309326171875e+00) (18, 3.85171264410018920898e-01) (19, 6.65323972702026367188e-01) (3, 2.07593321800231933594e+00) (4, 2.43764638900756835938e+00) (5, 1.55649375915527343750e+00) (6, 1.58439540863037109375e+00) (7, 4.19184398651123046875e+00) (8, 1.53073012828826904297e+00) (9, 1.77320182323455810547e+00) (10, 2.90178251266479492188e+00) (11, 1.60980403423309326172e+00) (12, 2.96477246284484863281e+00) (13, 1.96451199054718017578e+00) (14, 1.24503493309020996094e+00) (15, 2.87577080726623535156e+00) (16, 1.70917868614196777344e+00) (17, 3.18946623802185058594e+00) (18, 1.80888998508453369141e+00) (19, 8.76996278762817382812e-01) (3, 6.26643562316894531250e+00) (4, 7.34193420410156250000e+00) (5, 6.28021860122680664062e+00) (6, 5.82716417312622070312e+00) (7, 1.23717527389526367188e+01) (8, 6.13333559036254882812e+00) (9, 5.74191617965698242188e+00) (10, 8.73526287078857421875e+00) (11, 6.24372243881225585938e+00) (12, 6.30227708816528320312e+00) (13, 6.30026006698608398438e+00) (14, 8.72299861907958984375e+00) (15, 8.28555774688720703125e+00) (16, 5.76239299774169921875e+00) (17, 1.01693515777587890625e+01) (18, 5.78928136825561523438e+00) (19, 5.95982694625854492188e+00) 
