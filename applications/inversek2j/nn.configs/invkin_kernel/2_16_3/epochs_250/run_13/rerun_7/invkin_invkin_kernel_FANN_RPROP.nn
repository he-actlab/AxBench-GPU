FANN_FLO_2.1
num_layers=3
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=3 17 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -2.77306413650512695312e+00) (1, -1.33002269268035888672e+00) (2, 5.32173514366149902344e-01) (0, -3.40133190155029296875e+00) (1, -3.05778336524963378906e+00) (2, 6.72783032059669494629e-02) (0, -5.81781673431396484375e+00) (1, 5.50696849822998046875e-01) (2, 1.69888213276863098145e-01) (0, -2.35830736160278320312e+00) (1, 4.11151742935180664062e+00) (2, 1.35565733909606933594e+00) (0, -2.82527732849121093750e+00) (1, 2.27305054664611816406e+00) (2, 8.03898274898529052734e-01) (0, -3.31482577323913574219e+00) (1, 2.16765570640563964844e+00) (2, 7.76818811893463134766e-01) (0, -2.69372725486755371094e+00) (1, 2.47020888328552246094e+00) (2, 1.04328978061676025391e+00) (0, -2.67622375488281250000e+00) (1, -4.20106142759323120117e-01) (2, 2.52954888343811035156e+00) (0, -2.43135190010070800781e+00) (1, 2.76043128967285156250e+00) (2, 1.31659531593322753906e+00) (0, -1.44224607944488525391e+00) (1, -5.53331899642944335938e+00) (2, 8.99803936481475830078e-01) (0, -4.03217649459838867188e+00) (1, 1.19046819210052490234e+00) (2, 1.42025661468505859375e+00) (0, -7.54568052291870117188e+00) (1, -1.49234521389007568359e+00) (2, -5.80708086490631103516e-01) (0, -2.20682311058044433594e+00) (1, 8.63110637664794921875e+00) (2, -1.73658287525177001953e+00) (0, -3.81953215599060058594e+00) (1, 1.34412348270416259766e+00) (2, 6.97617590427398681641e-01) (0, -2.63902157545089721680e-01) (1, -1.83768332004547119141e+00) (2, 7.09866046905517578125e-01) (0, -2.30285143852233886719e+00) (1, 2.93725180625915527344e+00) (2, 1.77868354320526123047e+00) (3, -6.88773691654205322266e-02) (4, 2.43360805511474609375e+00) (5, 1.52127802371978759766e+00) (6, 4.08483535051345825195e-01) (7, 5.42831778526306152344e-01) (8, 6.16147458553314208984e-01) (9, 5.02780318260192871094e-01) (10, -4.21816796064376831055e-01) (11, 3.30041348934173583984e-01) (12, 1.88522434234619140625e+00) (13, 5.27686417102813720703e-01) (14, 1.38974368572235107422e+00) (15, 7.30589330196380615234e-01) (16, 6.15833878517150878906e-01) (17, -5.11404693126678466797e-01) (18, 4.67805176973342895508e-01) (19, 4.51695352792739868164e-01) (3, 3.18490338325500488281e+00) (4, 4.22510719299316406250e+00) (5, 2.42133116722106933594e+00) (6, 1.60421168804168701172e+00) (7, 1.61346185207366943359e+00) (8, 1.42320394515991210938e+00) (9, 1.58422386646270751953e+00) (10, 1.46676373481750488281e+00) (11, 1.67395484447479248047e+00) (12, 3.89672994613647460938e+00) (13, 1.82453334331512451172e+00) (14, 1.88679385185241699219e+00) (15, 2.18250417709350585938e+00) (16, 1.55680847167968750000e+00) (17, 2.61006164550781250000e+00) (18, 1.57020294666290283203e+00) (19, 1.26250398159027099609e+00) (3, 8.88781833648681640625e+00) (4, 1.22775354385375976562e+01) (5, 7.80701112747192382812e+00) (6, 6.88857746124267578125e+00) (7, 5.01141595840454101562e+00) (8, 5.10042572021484375000e+00) (9, 5.05965662002563476562e+00) (10, 5.08264350891113281250e+00) (11, 5.05802679061889648438e+00) (12, 8.83722019195556640625e+00) (13, 5.12766504287719726562e+00) (14, 6.62194919586181640625e+00) (15, 5.08607530593872070312e+00) (16, 5.01291990280151367188e+00) (17, 1.67061080932617187500e+01) (18, 6.97103977203369140625e+00) (19, 6.94763278961181640625e+00) 
