FANN_FLO_2.1
num_layers=3
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=3 17 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -2.60847663879394531250e+00) (1, -8.89256954193115234375e-01) (2, 7.37000346183776855469e-01) (0, -3.56489825248718261719e+00) (1, 3.21351504325866699219e+00) (2, 1.17683362960815429688e+00) (0, -4.34290742874145507812e+00) (1, -3.05509567260742187500e+00) (2, 5.96774756908416748047e-01) (0, -2.52927422523498535156e+00) (1, 3.68933558464050292969e+00) (2, 1.95257234573364257812e+00) (0, -2.67437481880187988281e+00) (1, 2.73073911666870117188e+00) (2, 3.23268508911132812500e+00) (0, -3.45473599433898925781e+00) (1, 2.01720476150512695312e+00) (2, 1.11290812492370605469e+00) (0, -2.55505561828613281250e+00) (1, 2.44215130805969238281e+00) (2, 3.16443300247192382812e+00) (0, -3.56605839729309082031e+00) (1, 1.68841207027435302734e+00) (2, 7.19205081462860107422e-01) (0, -1.21785771846771240234e+00) (1, -2.57235217094421386719e+00) (2, 7.18775033950805664062e-01) (0, -3.46518135070800781250e+00) (1, -1.11838304996490478516e+00) (2, 7.33157992362976074219e-01) (0, -2.65095448493957519531e+00) (1, 2.60848808288574218750e+00) (2, 3.28891277313232421875e+00) (0, -1.02965855598449707031e+00) (1, -5.02718305587768554688e+00) (2, 6.60603106021881103516e-01) (0, -2.63191437721252441406e+00) (1, 3.75849151611328125000e+00) (2, 1.41408622264862060547e+00) (0, -4.99267637729644775391e-01) (1, -1.04981505870819091797e+00) (2, 1.64482331275939941406e+00) (0, -3.90741157531738281250e+00) (1, 7.77457118034362792969e-01) (2, -2.42452099919319152832e-01) (0, -1.74197936058044433594e+00) (1, -2.61128354072570800781e+00) (2, 3.11105459928512573242e-01) (3, 7.56998717784881591797e-01) (4, 4.57808583974838256836e-01) (5, 1.27837121486663818359e+00) (6, 5.67296266555786132812e-01) (7, 4.47683274745941162109e-01) (8, 6.84953749179840087891e-01) (9, 3.15842390060424804688e-01) (10, 7.82575845718383789062e-01) (11, -1.77993988990783691406e+00) (12, 8.13497722148895263672e-01) (13, 3.60053330659866333008e-01) (14, 1.38153600692749023438e+00) (15, 4.55909669399261474609e-01) (16, -1.40063261985778808594e+00) (17, 1.77980494499206542969e+00) (18, 3.85527586936950683594e+00) (19, 7.82749652862548828125e-01) (3, 2.46591091156005859375e+00) (4, 1.55264282226562500000e+00) (5, 2.38630747795104980469e+00) (6, 1.82869684696197509766e+00) (7, 1.25649893283843994141e+00) (8, 2.60203814506530761719e+00) (9, 1.34035217761993408203e+00) (10, 2.66436886787414550781e+00) (11, 2.14608049392700195312e+00) (12, 2.50665259361267089844e+00) (13, 1.37323892116546630859e+00) (14, 3.06550407409667968750e+00) (15, 1.96481394767761230469e+00) (16, 3.53994369506835937500e-01) (17, 3.64622282981872558594e+00) (18, 3.61337804794311523438e+00) (19, 1.04347324371337890625e+00) (3, 6.80293750762939453125e+00) (4, 5.36969518661499023438e+00) (5, 6.87774896621704101562e+00) (6, 5.26497888565063476562e+00) (7, 5.31516742706298828125e+00) (8, 7.58644819259643554688e+00) (9, 5.34880828857421875000e+00) (10, 7.52384805679321289062e+00) (11, 9.12071514129638671875e+00) (12, 6.62020158767700195312e+00) (13, 5.27610445022583007812e+00) (14, 9.86794376373291015625e+00) (15, 5.33885383605957031250e+00) (16, 6.57653999328613281250e+00) (17, 1.37252187728881835938e+01) (18, 9.20111560821533203125e+00) (19, 5.28027820587158203125e+00) 
