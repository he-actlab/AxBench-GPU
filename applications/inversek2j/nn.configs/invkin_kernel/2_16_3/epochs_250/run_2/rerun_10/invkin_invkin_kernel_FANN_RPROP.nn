FANN_FLO_2.1
num_layers=3
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=3 17 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -2.84456896781921386719e+00) (1, -1.64944440126419067383e-01) (2, 2.05259561538696289062e+00) (0, -3.72008109092712402344e+00) (1, -2.33658146858215332031e+00) (2, 8.38094472885131835938e-01) (0, -2.69625997543334960938e+00) (1, 2.20858693122863769531e+00) (2, 4.53859233856201171875e+00) (0, -2.60228872299194335938e+00) (1, 1.94695091247558593750e+00) (2, 4.46563816070556640625e+00) (0, -3.10118675231933593750e+00) (1, 3.51592868566513061523e-01) (2, 2.12399601936340332031e+00) (0, -1.97259318828582763672e+00) (1, 1.20944082736968994141e+00) (2, 4.57456827163696289062e+00) (0, -2.90625286102294921875e+00) (1, 9.27449405193328857422e-01) (2, 1.15296995639801025391e+00) (0, -3.24170088768005371094e+00) (1, 1.72795462608337402344e+00) (2, 1.99558675289154052734e+00) (0, -1.75122416019439697266e+00) (1, -5.35042619705200195312e+00) (2, 4.32676821947097778320e-01) (0, -1.86472380161285400391e+00) (1, 2.82695245742797851562e+00) (2, 2.33779475092887878418e-01) (0, -3.51841282844543457031e+00) (1, 1.88449561595916748047e-01) (2, 1.03418767452239990234e+00) (0, -3.01581597328186035156e+00) (1, -4.09568977355957031250e+00) (2, 7.98616945743560791016e-01) (0, -3.69431972503662109375e+00) (1, 3.48474216461181640625e+00) (2, 3.56413340568542480469e+00) (0, -3.69971132278442382812e+00) (1, 2.90529966354370117188e+00) (2, 2.50966548919677734375e-01) (0, -3.52948737144470214844e+00) (1, 3.56150436401367187500e+00) (2, 3.50897002220153808594e+00) (0, -4.64107799530029296875e+00) (1, -8.64795207977294921875e-01) (2, 8.01746487617492675781e-01) (3, 8.39568018913269042969e-01) (4, 1.67883992195129394531e+00) (5, 3.22030782699584960938e-01) (6, 2.46225342154502868652e-01) (7, -3.30059498548507690430e-01) (8, 2.38848581910133361816e-01) (9, 6.27074539661407470703e-01) (10, 3.45238506793975830078e-01) (11, 1.02247548103332519531e+00) (12, 1.29560577869415283203e+00) (13, 7.50168502330780029297e-01) (14, 1.37675678730010986328e+00) (15, 3.37565243244171142578e-01) (16, 6.56374633312225341797e-01) (17, 3.80588889122009277344e-01) (18, 1.24163424968719482422e+00) (19, -2.56327707320451736450e-02) (3, 1.14025580883026123047e+00) (4, 4.44529199600219726562e+00) (5, 1.27308177947998046875e+00) (6, 1.31956028938293457031e+00) (7, 1.06560218334197998047e+00) (8, 1.30901980400085449219e+00) (9, 2.01681852340698242188e+00) (10, 1.19121980667114257812e+00) (11, 4.16041803359985351562e+00) (12, 2.57167267799377441406e+00) (13, 3.26665544509887695312e+00) (14, 3.69427776336669921875e+00) (15, 1.33352077007293701172e+00) (16, 1.50778758525848388672e+00) (17, 1.38066303730010986328e+00) (18, 2.51096510887145996094e+00) (19, 6.37991130352020263672e-01) (3, 6.94201374053955078125e+00) (4, 1.31064939498901367188e+01) (5, 5.10371112823486328125e+00) (6, 5.18921184539794921875e+00) (7, 4.77890634536743164062e+00) (8, 5.12151145935058593750e+00) (9, 5.85173320770263671875e+00) (10, 4.71637535095214843750e+00) (11, 1.35331029891967773438e+01) (12, 4.67013359069824218750e+00) (13, 5.52677726745605468750e+00) (14, 1.28349704742431640625e+01) (15, 5.11887693405151367188e+00) (16, 4.76173591613769531250e+00) (17, 5.17300176620483398438e+00) (18, 9.56871128082275390625e+00) (19, 5.06000041961669921875e+00) 
