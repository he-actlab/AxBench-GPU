FANN_FLO_2.1
num_layers=3
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=3 17 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -3.29684662818908691406e+00) (1, 3.18957948684692382812e+00) (2, 9.21826243400573730469e-01) (0, -3.83734607696533203125e+00) (1, 2.97817587852478027344e+00) (2, 1.33240520954132080078e-01) (0, -8.59953999519348144531e-01) (1, -8.43211233615875244141e-01) (2, 1.52701711654663085938e+00) (0, -2.43053460121154785156e+00) (1, 8.69294452667236328125e+00) (2, -3.29857259988784790039e-01) (0, -8.17368793487548828125e+00) (1, 6.90433084964752197266e-01) (2, -1.05599030852317810059e-01) (0, -2.27885341644287109375e+00) (1, 3.39789080619812011719e+00) (2, 1.14611732959747314453e+00) (0, -2.08611655235290527344e+00) (1, 2.67724180221557617188e+00) (2, 1.71425461769104003906e+00) (0, -4.12201070785522460938e+00) (1, -3.39935612678527832031e+00) (2, 1.65916025638580322266e-01) (0, -3.08898448944091796875e+00) (1, 6.73485040664672851562e-01) (2, 1.23997569084167480469e+00) (0, -2.93988299369812011719e+00) (1, 6.06421887874603271484e-01) (2, 1.33573651313781738281e+00) (0, -2.26314187049865722656e+00) (1, -1.05680656433105468750e+00) (2, 6.35390698909759521484e-01) (0, -7.50332689285278320312e+00) (1, -1.92235028743743896484e+00) (2, -2.06298679113388061523e-01) (0, -1.82120859622955322266e+00) (1, -1.43470323085784912109e+00) (2, 6.03175103664398193359e-01) (0, -1.93021833896636962891e+00) (1, 2.82921767234802246094e+00) (2, 1.70414674282073974609e+00) (0, -8.92267763614654541016e-01) (1, -2.65250444412231445312e+00) (2, 2.61987268924713134766e-01) (0, -3.08133864402770996094e+00) (1, 7.65222787857055664062e-01) (2, 1.03355085849761962891e+00) (3, 4.99777019023895263672e-01) (4, 1.34379673004150390625e+00) (5, -1.96423280239105224609e+00) (6, 8.32879722118377685547e-01) (7, 1.45945060253143310547e+00) (8, 3.82993131875991821289e-01) (9, 3.87904435396194458008e-01) (10, 2.09828329086303710938e+00) (11, 5.18422901630401611328e-01) (12, 3.33908766508102416992e-01) (13, 4.99802112579345703125e-01) (14, 1.14624106884002685547e+00) (15, 1.12423591315746307373e-01) (16, 3.79558116197586059570e-01) (17, 2.16616749763488769531e+00) (18, 4.68411028385162353516e-01) (19, 6.62387430667877197266e-01) (3, 2.36301636695861816406e+00) (4, 1.97727620601654052734e+00) (5, 2.81989097595214843750e-01) (6, 2.42508053779602050781e+00) (7, 2.35215044021606445312e+00) (8, 1.80575728416442871094e+00) (9, 1.83323538303375244141e+00) (10, 2.81635594367980957031e+00) (11, 1.72271716594696044922e+00) (12, 1.79313695430755615234e+00) (13, 1.67724430561065673828e+00) (14, 2.00748920440673828125e+00) (15, 1.66710233688354492188e+00) (16, 1.87076246738433837891e+00) (17, 7.38522815704345703125e+00) (18, 1.71167898178100585938e+00) (19, 3.83886963129043579102e-01) (3, 6.10433483123779296875e+00) (4, 6.14930009841918945312e+00) (5, 6.78561162948608398438e+00) (6, 7.14642810821533203125e+00) (7, 5.81748867034912109375e+00) (8, 7.20866012573242187500e+00) (9, 5.51814174652099609375e+00) (10, 6.36738300323486328125e+00) (11, 5.76531600952148437500e+00) (12, 5.84418296813964843750e+00) (13, 5.59636783599853515625e+00) (14, 5.66018533706665039062e+00) (15, 5.70452928543090820312e+00) (16, 5.48417568206787109375e+00) (17, 2.53426704406738281250e+01) (18, 5.92986011505126953125e+00) (19, 5.59369850158691406250e+00) 
