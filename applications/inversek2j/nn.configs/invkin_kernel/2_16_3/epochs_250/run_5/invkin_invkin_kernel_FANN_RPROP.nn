FANN_FLO_2.1
num_layers=3
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=3 17 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -2.25217366218566894531e+00) (1, 2.50427222251892089844e+00) (2, 3.45981192588806152344e+00) (0, -5.87295627593994140625e+00) (1, 1.08815991878509521484e+00) (2, -6.30102932453155517578e-01) (0, -2.24622344970703125000e+00) (1, 3.26047015190124511719e+00) (2, 2.90888023376464843750e+00) (0, -1.78236567974090576172e+00) (1, -3.76591491699218750000e+00) (2, 9.52130794525146484375e-01) (0, -2.84465909004211425781e+00) (1, 1.05877101421356201172e+00) (2, 1.25358760356903076172e+00) (0, -2.21676087379455566406e+00) (1, 1.57788908481597900391e+00) (2, 1.33880019187927246094e+00) (0, -2.31169366836547851562e+00) (1, 1.20457065105438232422e+00) (2, 1.36631917953491210938e+00) (0, -2.32346463203430175781e+00) (1, -1.20388889312744140625e+00) (2, 1.17417871952056884766e+00) (0, -1.94919025897979736328e+00) (1, 4.97193670272827148438e+00) (2, -6.93757891654968261719e-01) (0, -2.56852054595947265625e+00) (1, 3.35551357269287109375e+00) (2, 3.63533782958984375000e+00) (0, -2.91748285293579101562e+00) (1, 1.01803195476531982422e+00) (2, 1.30145001411437988281e+00) (0, -2.67447972297668457031e+00) (1, 1.13469433784484863281e+00) (2, 1.31358420848846435547e+00) (0, -2.82601499557495117188e+00) (1, 3.24666118621826171875e+00) (2, 1.41786861419677734375e+00) (0, -2.33575367927551269531e+00) (1, -1.20401573181152343750e+00) (2, 1.13853895664215087891e+00) (0, -5.21273517608642578125e+00) (1, -4.16715097427368164062e+00) (2, 8.06071579456329345703e-01) (0, -9.85081911087036132812e-01) (1, -3.31547698974609375000e+01) (2, 3.44925880432128906250e-01) (3, 1.72760501503944396973e-01) (4, 2.15005755424499511719e+00) (5, 1.68650388717651367188e-01) (6, 1.68485987186431884766e+00) (7, 3.99476200342178344727e-01) (8, 6.20789051055908203125e-01) (9, 5.18634855747222900391e-01) (10, 4.27307069301605224609e-01) (11, 1.49833333492279052734e+00) (12, 8.33782702684402465820e-02) (13, 2.51044124364852905273e-01) (14, 5.54804682731628417969e-01) (15, 2.67907351255416870117e-01) (16, 4.26854193210601806641e-01) (17, 1.65179681777954101562e+00) (18, 1.35025701522827148438e+01) (19, -3.13553512096405029297e-02) (3, 1.07022142410278320312e+00) (4, 3.04976153373718261719e+00) (5, 1.14725124835968017578e+00) (6, 5.81221628189086914062e+00) (7, 1.60667526721954345703e+00) (8, 1.88804566860198974609e+00) (9, 1.71765351295471191406e+00) (10, 2.93201041221618652344e+00) (11, 3.01215863227844238281e+00) (12, 1.14303946495056152344e+00) (13, 1.76266074180603027344e+00) (14, 1.56541144847869873047e+00) (15, 1.11709105968475341797e+00) (16, 2.89207482337951660156e+00) (17, 2.50055336952209472656e+00) (18, 3.46390953063964843750e+01) (19, 4.93644863367080688477e-01) (3, 5.28066587448120117188e+00) (4, 9.59641933441162109375e+00) (5, 5.25989151000976562500e+00) (6, 1.82899990081787109375e+01) (7, 5.28827428817749023438e+00) (8, 5.26150035858154296875e+00) (9, 5.33674526214599609375e+00) (10, 1.00954732894897460938e+01) (11, 5.26510953903198242188e+00) (12, 5.22189950942993164062e+00) (13, 5.32799148559570312500e+00) (14, 5.29602575302124023438e+00) (15, 5.30208826065063476562e+00) (16, 1.01272249221801757812e+01) (17, 6.27887535095214843750e+00) (18, 3.25087707519531250000e+02) (19, 5.18850803375244140625e+00) 
