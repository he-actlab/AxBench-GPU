FANN_FLO_2.1
num_layers=3
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=3 17 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -2.66435003280639648438e+00) (1, 3.73408436775207519531e+00) (2, 2.84824728965759277344e+00) (0, -3.25762557983398437500e+00) (1, 1.42568600177764892578e+00) (2, 1.19502687454223632812e+00) (0, -1.68135654926300048828e+00) (1, 2.44255280494689941406e+00) (2, 1.27161836624145507812e+00) (0, -3.12999820709228515625e+00) (1, 2.68738679587841033936e-02) (2, 9.26735162734985351562e-01) (0, -1.96100533008575439453e+00) (1, 2.64717125892639160156e+00) (2, 2.41889381408691406250e+00) (0, -7.55179738998413085938e+00) (1, -1.23481917381286621094e+00) (2, 9.31078553199768066406e-01) (0, -3.48099088668823242188e+00) (1, 1.40081930160522460938e+00) (2, 9.57177579402923583984e-01) (0, -3.05143356323242187500e+00) (1, 2.53903293609619140625e+00) (2, 1.80191266536712646484e+00) (0, -1.64510869979858398438e+00) (1, 2.82877993583679199219e+00) (2, 1.30203008651733398438e+00) (0, -2.32147669792175292969e+00) (1, -3.16192150115966796875e+00) (2, 8.36479425430297851562e-01) (0, -1.40816915035247802734e+00) (1, -9.21644389629364013672e-01) (2, 1.86884319782257080078e+00) (0, -1.89635694026947021484e+00) (1, -6.00924348831176757812e+00) (2, 7.10186243057250976562e-01) (0, -8.56202411651611328125e+00) (1, -5.13722610473632812500e+00) (2, 9.47958409786224365234e-01) (0, -3.13743710517883300781e+00) (1, 2.22745704650878906250e+00) (2, 2.02339863777160644531e+00) (0, -2.33460617065429687500e+00) (1, 3.17977380752563476562e+00) (2, 2.57007026672363281250e+00) (0, -3.11634016036987304688e+00) (1, 2.43124421685934066772e-02) (2, 9.19362604618072509766e-01) (3, 2.16935068368911743164e-01) (4, 9.65095758438110351562e-01) (5, 1.91514551639556884766e+00) (6, 7.33024537563323974609e-01) (7, 2.05290779471397399902e-01) (8, 1.57620823383331298828e+00) (9, 1.08479535579681396484e+00) (10, 2.12573781609535217285e-01) (11, 2.37104550004005432129e-01) (12, 1.47108864784240722656e+00) (13, -1.59560656547546386719e+00) (14, 1.71365678310394287109e+00) (15, 1.51720798015594482422e+00) (16, 2.27678999304771423340e-01) (17, 2.44182035326957702637e-01) (18, 7.56220459938049316406e-01) (19, -3.35910022258758544922e-02) (3, 1.44092214107513427734e+00) (4, 2.53986263275146484375e+00) (5, 1.72766077518463134766e+00) (6, 2.15866065025329589844e+00) (7, 1.26682138442993164062e+00) (8, 2.85803794860839843750e+00) (9, 2.42974829673767089844e+00) (10, 1.91954648494720458984e+00) (11, 1.34387481212615966797e+00) (12, 4.84546947479248046875e+00) (13, 1.24359548091888427734e-01) (14, 3.86867094039916992188e+00) (15, 2.54324626922607421875e+00) (16, 1.54863119125366210938e+00) (17, 1.42775630950927734375e+00) (18, 2.07766103744506835938e+00) (19, 5.30951976776123046875e-01) (3, 5.07953977584838867188e+00) (4, 6.90564775466918945312e+00) (5, 5.04858732223510742188e+00) (6, 6.79820299148559570312e+00) (7, 4.99031257629394531250e+00) (8, 6.72445917129516601562e+00) (9, 6.96052885055541992188e+00) (10, 5.01121520996093750000e+00) (11, 5.06407690048217773438e+00) (12, 1.46939439773559570312e+01) (13, 6.89146137237548828125e+00) (14, 1.25971813201904296875e+01) (15, 7.71410894393920898438e+00) (16, 5.06294488906860351562e+00) (17, 5.09203910827636718750e+00) (18, 6.70176601409912109375e+00) (19, 4.89726877212524414062e+00) 
