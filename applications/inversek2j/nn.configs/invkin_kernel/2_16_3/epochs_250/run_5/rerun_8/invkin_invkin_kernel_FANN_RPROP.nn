FANN_FLO_2.1
num_layers=3
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=3 17 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -3.42415976524353027344e+00) (1, 2.11482167243957519531e+00) (2, 3.12190389633178710938e+00) (0, -1.38702380657196044922e+00) (1, 2.73852205276489257812e+00) (2, 6.77589714527130126953e-01) (0, -7.43285608291625976562e+00) (1, -2.63280153274536132812e+00) (2, 2.88626122474670410156e+00) (0, -4.63138866424560546875e+00) (1, 9.21846091747283935547e-01) (2, 2.41152629256248474121e-01) (0, -2.57979526519775390625e+01) (1, -1.48483114242553710938e+01) (2, 5.13089418411254882812e+00) (0, -3.67337465286254882812e+00) (1, 1.57161939144134521484e+00) (2, 3.18902015686035156250e+00) (0, -4.54682397842407226562e+00) (1, -4.55443286895751953125e+00) (2, 6.80933237075805664062e-01) (0, -1.41930365562438964844e+00) (1, 2.78011894226074218750e+00) (2, 6.24387025833129882812e-01) (0, -3.95636010169982910156e+00) (1, -1.40544128417968750000e+00) (2, 5.31025028228759765625e+00) (0, -3.98744344711303710938e+00) (1, 1.15096414089202880859e+00) (2, 1.49094414710998535156e+00) (0, -2.45529723167419433594e+00) (1, 3.13520455360412597656e+00) (2, 3.46951007843017578125e+00) (0, -6.29775094985961914062e+00) (1, -1.75742685794830322266e+00) (2, 5.03843450546264648438e+00) (0, -2.49946618080139160156e+00) (1, 3.15982174873352050781e+00) (2, 3.54475593566894531250e+00) (0, -2.22597169876098632812e+00) (1, -6.23741292953491210938e+00) (2, 6.33589208126068115234e-01) (0, -3.17910432815551757812e+00) (1, 1.16630339622497558594e+00) (2, 1.70559227466583251953e+00) (0, -1.54214370250701904297e+00) (1, 2.73232054710388183594e+00) (2, -1.07489153742790222168e-01) (3, 2.53886580467224121094e-01) (4, 5.49580991268157958984e-01) (5, 1.46895241737365722656e+00) (6, 1.41333663463592529297e+00) (7, 7.43230819702148437500e-01) (8, 2.20990583300590515137e-01) (9, 1.59065437316894531250e+00) (10, 5.35851418972015380859e-01) (11, -8.82403314113616943359e-01) (12, 1.07165038585662841797e+00) (13, 3.29760581254959106445e-01) (14, 3.84254641830921173096e-02) (15, 2.94043064117431640625e-01) (16, 1.76095628738403320312e+00) (17, 8.08493852615356445312e-01) (18, 1.34944248199462890625e+00) (19, -1.74118846654891967773e-01) (3, 1.76865434646606445312e+00) (4, 1.64889311790466308594e+00) (5, 3.37287163734436035156e+00) (6, 1.98269498348236083984e+00) (7, 1.84056520462036132812e+00) (8, 1.55670404434204101562e+00) (9, 4.49606370925903320312e+00) (10, 1.70665216445922851562e+00) (11, 7.14885532855987548828e-01) (12, 1.95490598678588867188e+00) (13, 1.28240811824798583984e+00) (14, 1.24732530117034912109e+00) (15, 1.30479371547698974609e+00) (16, 4.79662513732910156250e+00) (17, 2.02737188339233398438e+00) (18, 2.48226332664489746094e+00) (19, 3.21974277496337890625e-01) (3, 6.11184215545654296875e+00) (4, 4.46177959442138671875e+00) (5, 1.00270385742187500000e+01) (6, 5.60804557800292968750e+00) (7, 5.81932449340820312500e+00) (8, 6.11273670196533203125e+00) (9, 1.47074012756347656250e+01) (10, 4.52719593048095703125e+00) (11, 4.45530223846435546875e+00) (12, 5.64749288558959960938e+00) (13, 6.05616950988769531250e+00) (14, 4.44751167297363281250e+00) (15, 6.04481935501098632812e+00) (16, 1.50319709777832031250e+01) (17, 5.68142843246459960938e+00) (18, 4.45312595367431640625e+00) (19, 5.97871780395507812500e+00) 
