FANN_FLO_2.1
num_layers=3
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=3 17 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -4.20942878723144531250e+00) (1, 1.13591186702251434326e-01) (2, 7.46224999427795410156e-01) (0, -2.46196508407592773438e+00) (1, 1.21698701381683349609e+00) (2, 1.28358566761016845703e+00) (0, -2.34242653846740722656e+00) (1, 5.60421848297119140625e+00) (2, 1.47718799114227294922e+00) (0, -2.27429008483886718750e+00) (1, 2.96849966049194335938e+00) (2, 2.15386486053466796875e+00) (0, -2.00930619239807128906e+00) (1, 3.88119864463806152344e+00) (2, 2.16875624656677246094e+00) (0, -2.62593460083007812500e+00) (1, 4.38167476654052734375e+00) (2, -6.65472984313964843750e-01) (0, -2.45345902442932128906e+00) (1, 1.25291502475738525391e+00) (2, 1.27168667316436767578e+00) (0, -1.02819442749023437500e+00) (1, -1.40461516380310058594e+00) (2, 8.62419366836547851562e-01) (0, -2.09669542312622070312e+00) (1, 2.98325228691101074219e+00) (2, 2.08117604255676269531e+00) (0, -2.54740071296691894531e+00) (1, 1.34226989746093750000e+00) (2, 1.19747459888458251953e+00) (0, -2.50139498710632324219e+00) (1, 1.30395972728729248047e+00) (2, 1.22300040721893310547e+00) (0, -1.69775593280792236328e+00) (1, -2.08415842056274414062e+00) (2, 1.09259593486785888672e+00) (0, -2.90031886100769042969e+00) (1, -5.50840902328491210938e+00) (2, 7.55376696586608886719e-01) (0, -8.03408741950988769531e-01) (1, -4.49562358856201171875e+00) (2, 5.20165741443634033203e-01) (0, -3.52273130416870117188e+00) (1, 7.58991718292236328125e-01) (2, 9.39743041992187500000e-01) (0, -4.54071283340454101562e+00) (1, -1.47105419635772705078e+00) (2, -1.21506182476878166199e-02) (3, 1.05858266353607177734e+00) (4, 3.99718731641769409180e-01) (5, 3.56208592653274536133e-01) (6, -3.69870029389858245850e-02) (7, 4.20436263084411621094e-01) (8, 1.67374038696289062500e+00) (9, 2.95896410942077636719e-01) (10, 1.02702271938323974609e+00) (11, 2.42812544107437133789e-01) (12, 3.52066874504089355469e-01) (13, 3.91143351793289184570e-01) (14, -1.30839419364929199219e+00) (15, 3.43911337852478027344e+00) (16, -1.12996160984039306641e+00) (17, 9.08321797847747802734e-01) (18, 2.64477086067199707031e+00) (19, 6.28534704446792602539e-02) (3, 2.82578873634338378906e+00) (4, 1.40760314464569091797e+00) (5, 1.27206289768218994141e+00) (6, 1.56292128562927246094e+00) (7, 1.37487459182739257812e+00) (8, 2.59003663063049316406e+00) (9, 1.49810326099395751953e+00) (10, 2.49946594238281250000e+00) (11, 1.60150516033172607422e+00) (12, 1.48650968074798583984e+00) (13, 1.51764631271362304688e+00) (14, 2.23110866546630859375e+00) (15, 3.82538032531738281250e+00) (16, 1.85427463054656982422e+00) (17, 2.57084202766418457031e+00) (18, 4.56439018249511718750e+00) (19, 4.95309531688690185547e-01) (3, 9.74094009399414062500e+00) (4, 5.32296323776245117188e+00) (5, 5.41679906845092773438e+00) (6, 5.38108921051025390625e+00) (7, 5.42012548446655273438e+00) (8, 5.31947469711303710938e+00) (9, 5.31471347808837890625e+00) (10, 8.18210124969482421875e+00) (11, 5.37144947052001953125e+00) (12, 5.33074474334716796875e+00) (13, 5.25929975509643554688e+00) (14, 9.73311901092529296875e+00) (15, 9.15655422210693359375e+00) (16, 9.62306594848632812500e+00) (17, 6.51050949096679687500e+00) (18, 1.32009487152099609375e+01) (19, 5.25806379318237304688e+00) 
