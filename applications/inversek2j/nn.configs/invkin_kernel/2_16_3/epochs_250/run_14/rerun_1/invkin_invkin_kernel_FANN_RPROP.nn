FANN_FLO_2.1
num_layers=3
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=3 17 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -2.83899903297424316406e+00) (1, 2.57396344095468521118e-02) (2, 9.08250570297241210938e-01) (0, -2.76911735534667968750e+00) (1, 1.94904541969299316406e+00) (2, 1.74425709247589111328e+00) (0, -2.73912405967712402344e+00) (1, 1.96026515960693359375e+00) (2, 1.60968935489654541016e+00) (0, -4.55222368240356445312e+00) (1, 2.25482606887817382812e+00) (2, -4.64539706707000732422e-01) (0, -4.34965229034423828125e+00) (1, -7.44757413864135742188e-01) (2, 6.16395771503448486328e-01) (0, -1.02932345867156982422e+00) (1, -1.54647457599639892578e+00) (2, 9.59727823734283447266e-01) (0, -1.51838433742523193359e+00) (1, 2.80905532836914062500e+00) (2, 1.01803386211395263672e+00) (0, -2.45006704330444335938e+00) (1, 3.28244781494140625000e+00) (2, 2.51983094215393066406e+00) (0, -2.78864693641662597656e+00) (1, 7.24443271756172180176e-02) (2, 1.06011164188385009766e+00) (0, -3.52992796897888183594e+00) (1, 2.15897464752197265625e+00) (2, 6.72726213932037353516e-01) (0, -3.20999407768249511719e+00) (1, 1.18098378181457519531e+00) (2, 1.17902135848999023438e+00) (0, -2.42719221115112304688e+00) (1, 2.06209564208984375000e+00) (2, 2.39727091789245605469e+00) (0, -1.61588788032531738281e+00) (1, 4.33878850936889648438e+00) (2, 2.15068385004997253418e-01) (0, -4.20541954040527343750e+00) (1, -2.52870416641235351562e+00) (2, 6.88337564468383789062e-01) (0, -1.13739633560180664062e+00) (1, -6.18125247955322265625e+00) (2, 1.29080152511596679688e+00) (0, -2.80700206756591796875e+00) (1, -4.31299448013305664062e+00) (2, 8.64166796207427978516e-01) (3, 8.16109418869018554688e-01) (4, 4.58073765039443969727e-01) (5, 3.81047964096069335938e-01) (6, 6.35321855545043945312e-01) (7, 1.08874154090881347656e+00) (8, -3.17209982872009277344e+00) (9, 6.06663763523101806641e-01) (10, 3.89417409896850585938e-01) (11, 6.77545130252838134766e-01) (12, 3.98984640836715698242e-01) (13, 4.94148790836334228516e-01) (14, 4.92372453212738037109e-01) (15, 6.49849534034729003906e-01) (16, 2.49303889274597167969e+00) (17, 1.09227466583251953125e+00) (18, 3.23333406448364257812e+00) (19, 4.10457462072372436523e-01) (3, 2.03262615203857421875e+00) (4, 1.48635697364807128906e+00) (5, 1.54463982582092285156e+00) (6, 1.37860262393951416016e+00) (7, 2.66176223754882812500e+00) (8, 1.78525674343109130859e+00) (9, 1.53972959518432617188e+00) (10, 1.68561637401580810547e+00) (11, 1.97523498535156250000e+00) (12, 1.69499838352203369141e+00) (13, 1.40498447418212890625e+00) (14, 1.47645640373229980469e+00) (15, 2.74945735931396484375e+00) (16, 3.78764104843139648438e+00) (17, 3.39050531387329101562e+00) (18, 3.73159646987915039062e+00) (19, 8.79347622394561767578e-01) (3, 7.40648984909057617188e+00) (4, 5.49451875686645507812e+00) (5, 5.57776784896850585938e+00) (6, 3.20868921279907226562e+00) (7, 7.45981836318969726562e+00) (8, 1.33479471206665039062e+01) (9, 5.72303724288940429688e+00) (10, 6.62173128128051757812e+00) (11, 7.37285423278808593750e+00) (12, 3.27676224708557128906e+00) (13, 4.78581380844116210938e+00) (14, 5.80972003936767578125e+00) (15, 6.67855787277221679688e+00) (16, 9.83484172821044921875e+00) (17, 1.10009593963623046875e+01) (18, 8.25916671752929687500e+00) (19, 6.53168439865112304688e+00) 
