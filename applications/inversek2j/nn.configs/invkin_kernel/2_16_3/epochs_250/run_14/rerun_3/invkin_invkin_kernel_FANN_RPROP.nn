FANN_FLO_2.1
num_layers=3
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=3 17 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -3.03334474563598632812e+00) (1, 5.98931312561035156250e-01) (2, 6.60928368568420410156e-01) (0, -5.07529211044311523438e+00) (1, -6.22832834720611572266e-01) (2, -3.86772781610488891602e-01) (0, -2.53388643264770507812e+00) (1, 4.41809082031250000000e+00) (2, 1.23181629180908203125e+00) (0, -3.49949336051940917969e+00) (1, 2.59184861183166503906e+00) (2, -1.73661664128303527832e-01) (0, -6.46956145763397216797e-01) (1, -8.83673310279846191406e-01) (2, 1.73570275306701660156e-01) (0, -3.31137442588806152344e+00) (1, 6.18576526641845703125e-01) (2, 6.47240757942199707031e-01) (0, -4.35275459289550781250e+00) (1, -3.12882685661315917969e+00) (2, 3.87969970703125000000e-01) (0, -1.39232850074768066406e+00) (1, -5.86933326721191406250e+00) (2, 2.44007587432861328125e+00) (0, -2.31928324699401855469e+00) (1, 3.60264778137207031250e+00) (2, 4.22004044055938720703e-01) (0, -2.35059666633605957031e+00) (1, 2.77653503417968750000e+00) (2, 6.12672567367553710938e-01) (0, -2.59343767166137695312e+00) (1, 7.90230274200439453125e+00) (2, 7.39420056343078613281e-01) (0, -2.72892212867736816406e+00) (1, 1.81519234180450439453e+00) (2, 6.14690423011779785156e-01) (0, -2.48175454139709472656e+00) (1, -8.30244660377502441406e-01) (2, 1.43456041812896728516e+00) (0, -7.95607209205627441406e-01) (1, -9.08667683601379394531e-01) (2, 2.12547615170478820801e-01) (0, -7.69844055175781250000e-01) (1, -9.38121438026428222656e-01) (2, 3.16399782896041870117e-01) (0, -7.76150822639465332031e-01) (1, -9.28478717803955078125e-01) (2, 2.87690669298171997070e-01) (3, 7.14773893356323242188e-01) (4, 2.08966946601867675781e+00) (5, 4.63237255811691284180e-01) (6, 6.69392526149749755859e-01) (7, -1.07217520475387573242e-01) (8, 8.12608063220977783203e-01) (9, 1.81934905052185058594e+00) (10, 1.69673717021942138672e+00) (11, 9.88587021827697753906e-01) (12, 9.03138041496276855469e-01) (13, 4.33401733636856079102e-01) (14, 7.74124741554260253906e-01) (15, -6.39443755149841308594e-01) (16, 4.06581640243530273438e-01) (17, -1.70961931347846984863e-01) (18, 2.21458151936531066895e-01) (19, 9.37089473009109497070e-02) (3, 2.17782926559448242188e+00) (4, 2.43177676200866699219e+00) (5, 2.01571655273437500000e+00) (6, 2.06689858436584472656e+00) (7, 9.30620193481445312500e-01) (8, 2.16480660438537597656e+00) (9, 3.02863359451293945312e+00) (10, 3.96965551376342773438e+00) (11, 2.24497914314270019531e+00) (12, 2.28167486190795898438e+00) (13, 2.06657528877258300781e+00) (14, 2.19872736930847167969e+00) (15, 1.79714596271514892578e+00) (16, 1.95138061046600341797e+00) (17, 1.47278630733489990234e+00) (18, 1.69034755229949951172e+00) (19, 8.97887349128723144531e-01) (3, 6.62462806701660156250e+00) (4, 6.56317901611328125000e+00) (5, 6.96283102035522460938e+00) (6, 6.63161754608154296875e+00) (7, 6.60873031616210937500e+00) (8, 6.55549240112304687500e+00) (9, 7.02492713928222656250e+00) (10, 1.17611150741577148438e+01) (11, 6.98430442810058593750e+00) (12, 6.95558881759643554688e+00) (13, 7.23566484451293945312e+00) (14, 6.50413513183593750000e+00) (15, 6.93798732757568359375e+00) (16, 6.64893674850463867188e+00) (17, 6.78121423721313476562e+00) (18, 6.84288978576660156250e+00) (19, 6.83013343811035156250e+00) 
