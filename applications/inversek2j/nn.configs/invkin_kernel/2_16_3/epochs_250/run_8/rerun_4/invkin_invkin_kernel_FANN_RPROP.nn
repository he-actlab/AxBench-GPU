FANN_FLO_2.1
num_layers=3
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=3 17 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.66218340396881103516e+00) (1, -2.81532692909240722656e+00) (2, 5.38137853145599365234e-01) (0, -1.14591765403747558594e+00) (1, -5.37004709243774414062e+00) (2, 6.67244791984558105469e-01) (0, -1.98785626888275146484e+00) (1, 2.27161478996276855469e+00) (2, 1.78661322593688964844e+00) (0, -7.71127748489379882812e+00) (1, 6.82880818843841552734e-01) (2, 6.09440743923187255859e-01) (0, -1.92978620529174804688e+00) (1, 2.18942427635192871094e+00) (2, 1.80437302589416503906e+00) (0, -6.60705280303955078125e+00) (1, -1.51056039333343505859e+00) (2, 1.32905513048171997070e-01) (0, -2.01515793800354003906e+00) (1, 2.27848386764526367188e+00) (2, 1.71027660369873046875e+00) (0, -3.50882577896118164062e+00) (1, 2.19337081909179687500e+00) (2, 1.46853303909301757812e+00) (0, -2.04117488861083984375e+00) (1, 4.74930095672607421875e+00) (2, 9.85907316207885742188e-01) (0, -1.82889091968536376953e+00) (1, 4.60677671432495117188e+00) (2, 6.40540838241577148438e-01) (0, -2.45626115798950195312e+00) (1, 2.05199074745178222656e+00) (2, 1.67870044708251953125e+00) (0, -3.14058375358581542969e+00) (1, 4.52988326549530029297e-01) (2, 1.92340731620788574219e+00) (0, -3.65800070762634277344e+00) (1, 1.39912652969360351562e+00) (2, 1.83929193019866943359e+00) (0, -3.87001323699951171875e+00) (1, 4.65307891368865966797e-01) (2, 1.91535830497741699219e+00) (0, -5.90808391571044921875e-01) (1, -1.12708020210266113281e+00) (2, 5.34043848514556884766e-01) (0, -5.16777658462524414062e+00) (1, -3.29713773727416992188e+00) (2, -8.68969038128852844238e-02) (3, 2.77949857711791992188e+00) (4, 1.48309147357940673828e+00) (5, 5.49255371093750000000e-01) (6, 1.25303804874420166016e+00) (7, 4.43039715290069580078e-01) (8, 1.43384468555450439453e+00) (9, 5.37178039550781250000e-01) (10, 9.11249876022338867188e-01) (11, 3.91619682312011718750e-01) (12, 3.37936013936996459961e-01) (13, 4.85481172800064086914e-01) (14, 3.22756230831146240234e-01) (15, 5.56312084197998046875e-01) (16, 3.94592851400375366211e-01) (17, -3.30641126632690429688e+00) (18, 1.99436819553375244141e+00) (19, 4.50217097997665405273e-01) (3, 4.19942760467529296875e+00) (4, 3.95654106140136718750e+00) (5, 1.50181853771209716797e+00) (6, 2.35780525207519531250e+00) (7, 1.36759757995605468750e+00) (8, 3.36281251907348632812e+00) (9, 1.86784482002258300781e+00) (10, 2.17303156852722167969e+00) (11, 1.54524946212768554688e+00) (12, 1.61893212795257568359e+00) (13, 1.66833043098449707031e+00) (14, 1.29038262367248535156e+00) (15, 2.19759225845336914062e+00) (16, 1.95899736881256103516e+00) (17, 9.52254295349121093750e-01) (18, 3.64291477203369140625e+00) (19, 5.08643686771392822266e-01) (3, 1.10398235321044921875e+01) (4, 1.21511421203613281250e+01) (5, 5.35485601425170898438e+00) (6, 7.24644327163696289062e+00) (7, 5.36801242828369140625e+00) (8, 9.85077857971191406250e+00) (9, 5.32186079025268554688e+00) (10, 5.62964487075805664062e+00) (11, 5.35208797454833984375e+00) (12, 5.21730184555053710938e+00) (13, 5.33348035812377929688e+00) (14, 5.33247375488281250000e+00) (15, 5.67319774627685546875e+00) (16, 7.16991806030273437500e+00) (17, 1.10746107101440429688e+01) (18, 9.92694664001464843750e+00) (19, 5.34164524078369140625e+00) 
