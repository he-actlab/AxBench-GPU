FANN_FLO_2.1
num_layers=3
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=3 17 4 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (3, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (17, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.14515221118927001953e+00) (1, -1.53835523128509521484e+00) (2, 9.35361862182617187500e-01) (0, -2.39870309829711914062e+00) (1, 5.12103509902954101562e+00) (2, 1.70629203319549560547e+00) (0, -7.40539312362670898438e-01) (1, -1.30552887916564941406e+00) (2, 8.25150310993194580078e-01) (0, -4.70276498794555664062e+00) (1, 1.03022706508636474609e+00) (2, 8.39564919471740722656e-01) (0, -3.07875728607177734375e+00) (1, 8.88958692550659179688e-01) (2, 1.42217099666595458984e+00) (0, -8.25625801086425781250e+00) (1, 3.20016086101531982422e-01) (2, 1.57368242740631103516e-01) (0, -4.81474685668945312500e+00) (1, -3.00184154510498046875e+00) (2, -9.30695310235023498535e-02) (0, -2.18702340126037597656e+00) (1, 3.72895479202270507812e+00) (2, 1.56441152095794677734e+00) (0, -2.03317761421203613281e+00) (1, 5.33852481842041015625e+00) (2, 6.80785238742828369141e-01) (0, -1.64860212802886962891e+00) (1, -4.92999315261840820312e+00) (2, 1.05778801441192626953e+00) (0, -2.60665774345397949219e+00) (1, 2.38155746459960937500e+00) (2, 1.50354254245758056641e+00) (0, -2.29884934425354003906e+00) (1, -2.50214159488677978516e-01) (2, 1.84333479404449462891e+00) (0, -4.07587814331054687500e+00) (1, 2.66711282730102539062e+00) (2, 6.79558157920837402344e-01) (0, -2.41152667999267578125e+00) (1, 2.25567007064819335938e+00) (2, 1.54171192646026611328e+00) (0, -2.39179468154907226562e+00) (1, 2.48436903953552246094e+00) (2, 1.60419154167175292969e+00) (0, -7.57407522201538085938e+00) (1, -1.51433181762695312500e+00) (2, -3.41794878244400024414e-01) (3, 2.02604740858078002930e-01) (4, 3.30946862697601318359e-01) (5, -1.69053912162780761719e+00) (6, 1.40795016288757324219e+00) (7, 5.30771672725677490234e-01) (8, 1.00460350513458251953e+00) (9, 2.40853929519653320312e+00) (10, 5.34307420253753662109e-01) (11, 3.72872859239578247070e-01) (12, 2.74462342262268066406e+00) (13, 5.63635945320129394531e-01) (14, -7.02403366565704345703e-01) (15, 9.12540793418884277344e-01) (16, 5.75222849845886230469e-01) (17, 5.66244065761566162109e-01) (18, 1.01726901531219482422e+00) (19, 4.16208744049072265625e-01) (3, 2.14444494247436523438e+00) (4, 9.34306204319000244141e-01) (5, 1.17629003524780273438e+00) (6, 1.57430529594421386719e+00) (7, 2.32601475715637207031e+00) (8, 2.36950278282165527344e+00) (9, 3.80628466606140136719e+00) (10, 2.09424114227294921875e+00) (11, 1.16253387928009033203e+00) (12, 5.06079673767089843750e+00) (13, 2.02480578422546386719e+00) (14, 1.42494237422943115234e+00) (15, 1.94697630405426025391e+00) (16, 2.03468394279479980469e+00) (17, 2.05000686645507812500e+00) (18, 2.01043415069580078125e+00) (19, 7.25591063499450683594e-01) (3, 9.23301124572753906250e+00) (4, 5.77588129043579101562e+00) (5, 9.13615322113037109375e+00) (6, 7.82015466690063476562e+00) (7, 5.17003393173217773438e+00) (8, 5.21611022949218750000e+00) (9, 9.18253707885742187500e+00) (10, 5.29570341110229492188e+00) (11, 5.77509975433349609375e+00) (12, 1.35704164505004882812e+01) (13, 5.20181655883789062500e+00) (14, 5.20076608657836914062e+00) (15, 7.83463859558105468750e+00) (16, 5.30569028854370117188e+00) (17, 5.27484416961669921875e+00) (18, 6.46921157836914062500e+00) (19, 5.65629339218139648438e+00) 
