FANN_FLO_2.1
num_layers=3
learning_rate=0.300000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=4 33 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (33, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -5.37743568420410156250e-01) (1, 2.68428951501846313477e-01) (2, -7.83351659774780273438e-01) (3, -3.46375554800033569336e-01) (0, -1.67535519599914550781e+00) (1, -1.74966692924499511719e-01) (2, -1.31903219223022460938e+01) (3, -4.36745136976242065430e-01) (0, -6.70883893966674804688e-01) (1, 5.21278858184814453125e-01) (2, -1.06333076953887939453e+00) (3, 1.33895683288574218750e+00) (0, -1.25881552696228027344e-01) (1, -1.07664233073592185974e-02) (2, -2.29230254888534545898e-01) (3, 5.20229911804199218750e+00) (0, 1.57698202133178710938e+00) (1, 8.56259018182754516602e-02) (2, -1.90046882629394531250e+01) (3, 4.74841028451919555664e-01) (0, 3.55780631303787231445e-01) (1, -1.92590460181236267090e-01) (2, -4.15451507568359375000e+01) (3, -1.51861339807510375977e-01) (0, 3.75627779960632324219e+00) (1, 6.74247562885284423828e-01) (2, 1.27140861511230468750e+02) (3, 4.03978973627090454102e-01) (0, -5.01401603221893310547e-01) (1, 3.59626621007919311523e-01) (2, -6.02400958538055419922e-01) (3, 4.79170650243759155273e-01) (0, -1.99045133590698242188e+00) (1, -1.13599136471748352051e-01) (2, -1.32191858291625976562e+01) (3, -4.17069822549819946289e-01) (0, -1.63946115970611572266e+00) (1, -2.12953984737396240234e-01) (2, -1.31432924270629882812e+01) (3, -3.33042502403259277344e-01) (0, -4.47894096374511718750e+00) (1, -3.34987074136734008789e-01) (2, 7.08419740200042724609e-01) (3, 1.31372034549713134766e-01) (0, 3.68341535329818725586e-01) (1, -1.94235071539878845215e-01) (2, -4.15221405029296875000e+01) (3, -1.19563989341259002686e-01) (0, -5.67127108573913574219e-01) (1, 3.88182580471038818359e-01) (2, -9.67305004596710205078e-01) (3, 1.78551983833312988281e+00) (0, -1.72401809692382812500e+00) (1, -1.96683913469314575195e-01) (2, -1.31148624420166015625e+01) (3, -3.33954900503158569336e-01) (0, -2.64149904251098632812e-01) (1, 3.37518036365509033203e-01) (2, -5.92082552611827850342e-02) (3, 7.28126347064971923828e-01) (0, -2.25751206278800964355e-01) (1, 5.14452934265136718750e-01) (2, -1.04320478439331054688e+00) (3, 8.80212843418121337891e-01) (0, 1.33823812007904052734e+00) (1, -3.33011537790298461914e-01) (2, -3.51782274246215820312e+00) (3, 5.05021475255489349365e-02) (0, 2.42544665932655334473e-01) (1, -7.92123377323150634766e-02) (2, 5.51121890544891357422e-01) (3, -2.08151221275329589844e+00) (0, -2.98860579729080200195e-01) (1, 3.65875363349914550781e-01) (2, -2.11046174168586730957e-01) (3, 9.30143296718597412109e-01) (0, -3.47629725933074951172e-01) (1, 4.74540442228317260742e-01) (2, -7.19369292259216308594e-01) (3, 1.52896964550018310547e+00) (0, 4.26685184240341186523e-01) (1, 1.72144532203674316406e-01) (2, -1.88141231536865234375e+01) (3, 1.60510033369064331055e-01) (0, -3.05472230911254882812e+00) (1, 3.21930311620235443115e-02) (2, 4.04007703065872192383e-01) (3, 1.65232643485069274902e-01) (0, -1.70560383796691894531e+00) (1, -1.97252511978149414062e-01) (2, -1.32232780456542968750e+01) (3, -4.14750427007675170898e-01) (0, 3.92065197229385375977e-01) (1, -1.98034271597862243652e-01) (2, -4.14807281494140625000e+01) (3, -5.84671124815940856934e-02) (0, 3.70245528221130371094e+00) (1, 6.29249095916748046875e-01) (2, 1.35358016967773437500e+02) (3, 3.49980175495147705078e-01) (0, -5.14742136001586914062e-01) (1, 3.84087592363357543945e-01) (2, -7.32048094272613525391e-01) (3, 1.09288048744201660156e+00) (0, 3.33962678909301757812e+00) (1, -4.48661029338836669922e-01) (2, -1.49617156982421875000e+01) (3, -3.27609479427337646484e-02) (0, -4.89937871694564819336e-01) (1, -4.08110260963439941406e-01) (2, -2.08707923889160156250e+01) (3, -8.25604051351547241211e-02) (0, 2.42691799998283386230e-01) (1, -1.38061270117759704590e-01) (2, -2.55961275100708007812e+00) (3, 2.52947479486465454102e-01) (0, -1.44848811626434326172e+00) (1, -2.68965184688568115234e-01) (2, 1.88361084461212158203e+00) (3, 2.06261649727821350098e-01) (0, -5.61561048030853271484e-01) (1, 3.01832675933837890625e-01) (2, -6.40745937824249267578e-01) (3, 7.73487210273742675781e-01) (0, 1.33819174766540527344e+00) (1, -3.36184173822402954102e-01) (2, -4.96096420288085937500e+00) (3, -1.55689835548400878906e-01) (4, -4.88096833229064941406e-01) (5, -1.50000000000000000000e+03) (6, -1.15129321813583374023e-01) (7, -2.72921061515808105469e+00) (8, -1.50000000000000000000e+03) (9, 1.50000000000000000000e+03) (10, -3.09289619326591491699e-02) (11, -2.06560149788856506348e-01) (12, -1.50000000000000000000e+03) (13, -1.50000000000000000000e+03) (14, 1.50000000000000000000e+03) (15, 1.50000000000000000000e+03) (16, -4.01576191186904907227e-01) (17, -1.50000000000000000000e+03) (18, -1.66578203439712524414e-01) (19, -9.21758487820625305176e-02) (20, -2.56411876678466796875e+01) (21, 2.07843017578125000000e+00) (22, -1.40965148806571960449e-01) (23, -9.26500633358955383301e-02) (24, -1.50000000000000000000e+03) (25, -1.50000000000000000000e+03) (26, -1.50000000000000000000e+03) (27, 1.50000000000000000000e+03) (28, -3.12546603381633758545e-02) (29, -2.26400926709175109863e-01) (30, 2.77382202148437500000e+02) (31, 1.50000000000000000000e+03) (32, -4.71198005676269531250e+01) (33, -9.32646606445312500000e+02) (34, -4.41720545291900634766e-01) (35, 1.74455596923828125000e+02) (36, -1.97249874472618103027e-02) 
