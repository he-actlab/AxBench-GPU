FANN_FLO_2.1
num_layers=3
learning_rate=0.300000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=4 17 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (17, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -2.55296260118484497070e-01) (1, 4.49920743703842163086e-01) (2, -3.08704018592834472656e+00) (3, 5.10905146598815917969e-01) (0, -1.13309510052204132080e-01) (1, 5.32996416091918945312e-01) (2, -3.49863862991333007812e+00) (3, 1.75848305225372314453e+00) (0, -4.46892768144607543945e-01) (1, 4.73298400640487670898e-01) (2, -2.44676542282104492188e+00) (3, 7.32033348083496093750e+00) (0, -2.74820983409881591797e-01) (1, 5.65442383289337158203e-01) (2, -3.66415858268737792969e+00) (3, 5.82422637939453125000e+00) (0, 9.06685256958007812500e+00) (1, -3.31096917390823364258e-01) (2, -4.88620185852050781250e+01) (3, -3.83872911334037780762e-02) (0, -7.47159659862518310547e-01) (1, 3.98078233003616333008e-01) (2, -1.13734781742095947266e+00) (3, 3.40033698081970214844e+00) (0, -7.90674746036529541016e-01) (1, 5.67909300327301025391e-01) (2, -1.22477483749389648438e+00) (3, 1.70480585098266601562e+00) (0, 6.35411024093627929688e+00) (1, -3.36754262447357177734e-01) (2, -4.80986022949218750000e+01) (3, -8.98670181632041931152e-02) (0, -4.30112987756729125977e-01) (1, 5.17709732055664062500e-01) (2, -3.68346285820007324219e+00) (3, -1.03239798545837402344e+00) (0, -8.81482315063476562500e+00) (1, -3.12285184860229492188e-01) (2, -4.37176799774169921875e+00) (3, -6.98543861508369445801e-02) (0, 7.60928452014923095703e-01) (1, 4.32496994733810424805e-01) (2, -3.84406638145446777344e+00) (3, 4.57806318998336791992e-01) (0, -4.45103287696838378906e-01) (1, 2.73666799068450927734e-01) (2, -3.33001565933227539062e+00) (3, 2.68990874290466308594e-01) (0, 8.66627120971679687500e+00) (1, -3.26066523790359497070e-01) (2, -4.71399841308593750000e+01) (3, -3.28859388828277587891e-02) (0, -2.38437190651893615723e-01) (1, 3.30705232918262481689e-02) (2, -5.04233598709106445312e-01) (3, 6.27762651443481445312e+00) (0, 8.67364788055419921875e+00) (1, -3.26770156621932983398e-01) (2, -4.69803771972656250000e+01) (3, -1.15925393998622894287e-01) (0, 8.87390017509460449219e-01) (1, 1.07663400471210479736e-01) (2, -2.97182607650756835938e+00) (3, 3.89478385448455810547e-01) (4, -9.69470366835594177246e-02) (5, -5.06719127297401428223e-02) (6, -9.02714580297470092773e-02) (7, -1.31319090723991394043e-01) (8, -9.23085556030273437500e+01) (9, -3.05405497550964355469e-01) (10, -4.64324980974197387695e-01) (11, 1.45000000000000000000e+03) (12, -2.08526208996772766113e-01) (13, -1.50000000000000000000e+03) (14, 2.83325731754302978516e-01) (15, -3.82889246940612792969e+00) (16, 1.59782333374023437500e+02) (17, -3.24981999397277832031e+00) (18, 1.59786575317382812500e+02) (19, 3.33762466907501220703e-01) (20, 6.51538819074630737305e-02) 
