FANN_FLO_2.1
num_layers=3
learning_rate=0.300000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=4 17 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (17, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -5.98852992057800292969e-01) (1, 3.41623455286026000977e-01) (2, -6.52984201908111572266e-01) (3, 8.26625645160675048828e-01) (0, -1.34591889381408691406e+00) (1, -9.74794089794158935547e-01) (2, 5.95286130905151367188e+00) (3, -1.29425942897796630859e-01) (0, -8.25924158096313476562e-01) (1, 3.86165916919708251953e-01) (2, -4.15687859058380126953e-01) (3, 3.47505307197570800781e+00) (0, 5.18219757080078125000e+00) (1, -2.70676046609878540039e-01) (2, -2.17457065582275390625e+01) (3, -1.57185450196266174316e-01) (0, -9.37714457511901855469e-01) (1, 4.47118133306503295898e-01) (2, -3.74367117881774902344e-01) (3, 2.77969908714294433594e+00) (0, -4.59939146041870117188e+00) (1, -8.45472216606140136719e-01) (2, 6.06426382064819335938e+00) (3, 3.37672531604766845703e-02) (0, -6.33867204189300537109e-01) (1, 2.86779791116714477539e-01) (2, -6.35685503482818603516e-01) (3, 6.27382814884185791016e-01) (0, -9.93432922363281250000e+02) (1, -1.15619058609008789062e+01) (2, -1.68283786773681640625e+01) (3, -3.33224609494209289551e-02) (0, -4.84182643890380859375e+00) (1, 1.17113006114959716797e+00) (2, -1.90263957977294921875e+01) (3, 3.65496337413787841797e-01) (0, 5.37526130676269531250e+00) (1, -2.70594179630279541016e-01) (2, -2.27322406768798828125e+01) (3, -8.36961418390274047852e-02) (0, -6.64081513881683349609e-01) (1, 3.26165884733200073242e-01) (2, -3.68991613388061523438e-01) (3, 1.87219834327697753906e+00) (0, -1.90080329775810241699e-01) (1, 3.72553877532482147217e-02) (2, -3.77774685621261596680e-01) (3, 5.10864734649658203125e+00) (0, -2.53239780664443969727e-01) (1, 3.57213653624057769775e-02) (2, -4.41018700599670410156e-01) (3, 2.86727404594421386719e+00) (0, 7.26802170276641845703e-01) (1, -5.36298155784606933594e-01) (2, 9.06397819519042968750e-01) (3, -4.68874484300613403320e-01) (0, -1.02161121368408203125e+00) (1, -1.04072415828704833984e+00) (2, 5.87388753890991210938e+00) (3, -1.80848196148872375488e-01) (0, 1.87347519397735595703e+00) (1, -4.75190311670303344727e-01) (2, -3.29603052139282226562e+00) (3, -1.65568038821220397949e-01) (4, -4.10724021494388580322e-02) (5, -1.66676330566406250000e+01) (6, -5.20985797047615051270e-02) (7, 8.22854309082031250000e+01) (8, -1.06296017765998840332e-01) (9, 1.50000000000000000000e+03) (10, -9.04757976531982421875e-02) (11, 1.50000000000000000000e+03) (12, -1.50000000000000000000e+03) (13, -8.19260635375976562500e+01) (14, -1.06866680085659027100e-01) (15, -2.78770685195922851562e+00) (16, -6.36536216735839843750e+00) (17, 8.36339473724365234375e-01) (18, 4.98767204284667968750e+01) (19, -5.94358623027801513672e-01) (20, 6.41391932964324951172e-01) 
