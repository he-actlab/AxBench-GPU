FANN_FLO_2.1
num_layers=3
learning_rate=0.300000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=4 17 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (4, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (17, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -9.40202295780181884766e-01) (1, 3.22250336408615112305e-01) (2, -1.19410240650177001953e+00) (3, 1.46197481155395507812e+01) (0, -4.04851293563842773438e+00) (1, 1.29321113228797912598e-01) (2, -8.12541961669921875000e+00) (3, 6.26267731189727783203e-01) (0, -5.34501254558563232422e-01) (1, 4.55770671367645263672e-01) (2, -2.22853622436523437500e+01) (3, 1.64147391915321350098e-01) (0, -1.19843888282775878906e+00) (1, 4.58295077085494995117e-01) (2, -8.66042912006378173828e-01) (3, 4.88345766067504882812e+00) (0, 3.96183943748474121094e+00) (1, -2.18396449089050292969e+00) (2, -8.68693576194345951080e-04) (3, -2.09937542676925659180e-02) (0, 1.29459440708160400391e-01) (1, -4.80295382440090179443e-02) (2, 6.86603009700775146484e-01) (3, -4.30008411407470703125e+00) (0, 4.04305124282836914062e+00) (1, -2.14506435394287109375e+00) (2, -5.88547170162200927734e-01) (3, -4.45274971425533294678e-02) (0, -1.90815970301628112793e-01) (1, 2.37037427723407745361e-02) (2, -2.83199131488800048828e-01) (3, 3.68610358238220214844e+00) (0, -9.51643407344818115234e-01) (1, 6.47386074066162109375e-01) (2, -9.47574973106384277344e-01) (3, 5.16316473484039306641e-01) (0, 1.28380024433135986328e+00) (1, -1.63610148429870605469e+00) (2, -3.83532667160034179688e+00) (3, 6.16824626922607421875e-01) (0, -2.13066577911376953125e+00) (1, 6.10131304711103439331e-03) (2, 1.07882484793663024902e-01) (3, 1.71984091401100158691e-01) (0, -3.26850146055221557617e-01) (1, -1.13932184875011444092e-01) (2, -2.23325271606445312500e+01) (3, 1.66866872459650039673e-02) (0, -4.46033179759979248047e-01) (1, -6.92489445209503173828e-02) (2, -2.24488296508789062500e+01) (3, 1.06083437800407409668e-01) (0, -8.40434789657592773438e-01) (1, 6.15055739879608154297e-01) (2, -1.11410510540008544922e+00) (3, 5.53497970104217529297e-01) (0, -4.09556913375854492188e+00) (1, 8.58671069145202636719e-01) (2, -2.11531429290771484375e+01) (3, 8.15037727355957031250e-01) (0, 4.09990167617797851562e+00) (1, -2.18913292884826660156e+00) (2, -5.29074907302856445312e-01) (3, 6.29178574308753013611e-03) (4, -3.26986074447631835938e-01) (5, -1.50000000000000000000e+03) (6, -1.50000000000000000000e+03) (7, -1.99332594871520996094e-01) (8, -8.82959842681884765625e-01) (9, 1.04959475994110107422e+00) (10, -2.20798969268798828125e+00) (11, -3.84310650825500488281e+00) (12, -3.19495230913162231445e-01) (13, -1.45000000000000000000e+03) (14, -1.50000000000000000000e+03) (15, 1.50000000000000000000e+03) (16, 1.50000000000000000000e+03) (17, -2.98433214426040649414e-01) (18, -1.50000000000000000000e+03) (19, 3.10266757011413574219e+00) (20, -2.46739208698272705078e-01) 
