FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=18 5 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.41169681549072265625e+01) (1, 1.47530632019042968750e+01) (2, 1.54716863632202148438e+01) (3, 1.33446531295776367188e+01) (4, 4.21093368530273437500e+00) (5, 7.27697849273681640625e+00) (6, 4.44040966033935546875e+00) (7, 4.24088621139526367188e+00) (8, 2.64400434494018554688e+00) (9, -5.98000586032867431641e-01) (10, 1.38658475875854492188e+01) (11, -2.45562171936035156250e+01) (12, 9.76247215270996093750e+00) (13, 1.35690240859985351562e+01) (14, 8.65207004547119140625e+00) (15, 1.22308216094970703125e+01) (16, -3.14543318748474121094e+00) (17, 2.23597216606140136719e+00) (0, 1.23171627521514892578e+00) (1, 7.92822420597076416016e-01) (2, 4.17706578969955444336e-01) (3, 1.03530120849609375000e+00) (4, 1.77658602595329284668e-01) (5, -2.59941313415765762329e-02) (6, -1.19305074214935302734e+00) (7, -3.63096058368682861328e-01) (8, 5.55553615093231201172e-01) (9, 7.91994094848632812500e-01) (10, 7.69890964031219482422e-01) (11, 9.29436206817626953125e-01) (12, 1.57259285449981689453e+00) (13, 1.27072763442993164062e+00) (14, 7.55781352519989013672e-01) (15, 7.70943582057952880859e-01) (16, 6.83988690376281738281e-01) (17, -5.73040008544921875000e+00) (0, 1.52403211593627929688e+00) (1, 1.34741580486297607422e+00) (2, 1.09622573852539062500e+00) (3, 1.09549772739410400391e+00) (4, 3.62842112779617309570e-01) (5, 2.31915727257728576660e-01) (6, -3.78297418355941772461e-01) (7, -4.11341339349746704102e-01) (8, 7.04612612724304199219e-01) (9, 7.14925348758697509766e-01) (10, 8.58292043209075927734e-01) (11, 1.18147540092468261719e+00) (12, 2.10946631431579589844e+00) (13, 1.31898939609527587891e+00) (14, 7.08484232425689697266e-01) (15, 1.04610383510589599609e+00) (16, 1.12292885780334472656e+00) (17, -5.60984230041503906250e+00) (0, -7.90975093841552734375e-02) (1, -1.30520045757293701172e+00) (2, -1.72976195812225341797e+00) (3, -1.74318253993988037109e+00) (4, -3.57096314430236816406e+00) (5, 5.18734788894653320312e+00) (6, 2.16446280479431152344e+00) (7, 3.52373003959655761719e+00) (8, 2.11760091781616210938e+00) (9, -2.24453234672546386719e+00) (10, -1.42986607551574707031e+00) (11, -2.15117883682250976562e+00) (12, 1.61652934551239013672e+00) (13, -7.37844705581665039062e-01) (14, -1.66893053054809570312e+00) (15, -1.84456622600555419922e+00) (16, -1.94594562053680419922e+00) (17, 2.30147099494934082031e+00) (18, -5.53771853446960449219e-01) (19, 1.99644589424133300781e+00) (20, 2.07533383369445800781e+00) (21, -5.16611814498901367188e-01) (22, -6.92236840724945068359e-01) (18, 1.71054375171661376953e+00) (19, 1.50000000000000000000e+03) (20, 1.50000000000000000000e+03) (21, -1.63048873901367187500e+02) (22, 1.68842828273773193359e+00) (18, -9.23325121402740478516e-01) (19, 1.92452752590179443359e+00) (20, 1.55425882339477539062e+00) (21, -1.70185172557830810547e+00) (22, -9.36780333518981933594e-01) (18, 2.98150986433029174805e-01) (19, 3.17303066253662109375e+01) (20, 1.67739429473876953125e+01) (21, -7.09394693374633789062e+00) (22, 2.54487454891204833984e-01) (23, 4.92893314361572265625e+00) (24, 1.53090357780456542969e+00) (25, 5.64450979232788085938e+00) (26, 1.32660150527954101562e+00) (27, 1.54191923141479492188e+00) 
