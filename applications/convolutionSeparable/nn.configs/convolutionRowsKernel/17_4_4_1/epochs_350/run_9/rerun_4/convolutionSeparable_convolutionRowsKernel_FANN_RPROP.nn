FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=18 5 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 6.54433131217956542969e-01) (1, 8.48159253597259521484e-01) (2, 6.54147148132324218750e-01) (3, 5.77848374843597412109e-01) (4, 7.45729863643646240234e-01) (5, -1.36014297604560852051e-01) (6, -5.63940405845642089844e-01) (7, -7.35595583915710449219e-01) (8, 3.19812446832656860352e-01) (9, 7.08511888980865478516e-01) (10, 6.63928985595703125000e-01) (11, 6.10638797283172607422e-01) (12, 1.04620730876922607422e+00) (13, 4.80499476194381713867e-01) (14, 7.25535631179809570312e-01) (15, 6.88485682010650634766e-01) (16, 7.83202350139617919922e-01) (17, -3.64640903472900390625e+00) (0, 6.98946833610534667969e-01) (1, 6.14065349102020263672e-01) (2, 7.75163710117340087891e-01) (3, 7.72300124168395996094e-01) (4, 5.45621812343597412109e-01) (5, -6.72319471836090087891e-01) (6, -6.60179376602172851562e-01) (7, 1.73739623278379440308e-02) (8, 7.10695743560791015625e-01) (9, 6.55735313892364501953e-01) (10, 7.68981456756591796875e-01) (11, 5.58104217052459716797e-01) (12, 1.13193190097808837891e+00) (13, 5.50866067409515380859e-01) (14, 6.63000106811523437500e-01) (15, 8.22921454906463623047e-01) (16, 6.33514225482940673828e-01) (17, -4.15635919570922851562e+00) (0, -1.32383430004119873047e+00) (1, -1.24545800685882568359e+00) (2, -1.00303244590759277344e+00) (3, -2.01157450675964355469e+00) (4, -9.18532729148864746094e-01) (5, 2.08152389526367187500e+00) (6, 2.67845249176025390625e+00) (7, 1.93328988552093505859e+00) (8, 1.95278215408325195312e+00) (9, -1.03106606006622314453e+00) (10, -9.00361895561218261719e-01) (11, -2.16971135139465332031e+00) (12, 8.31523001194000244141e-01) (13, -2.45267057418823242188e+00) (14, -7.50142693519592285156e-01) (15, -9.68965709209442138672e-01) (16, -1.06941020488739013672e+00) (17, 2.82292413711547851562e+00) (0, -2.33061611652374267578e-01) (1, 1.14890041351318359375e+01) (2, 9.94539111852645874023e-02) (3, 4.54861909151077270508e-01) (4, -2.20903968811035156250e+00) (5, 6.09800291061401367188e+00) (6, 1.59819126129150390625e+00) (7, -2.25893235206604003906e+00) (8, -4.59441423416137695312e+00) (9, -2.51229000091552734375e+00) (10, -6.17150354385375976562e+00) (11, -5.99354839324951171875e+00) (12, -1.39282298088073730469e+00) (13, -4.18612194061279296875e+00) (14, -1.22926568984985351562e+01) (15, -1.43968267440795898438e+01) (16, -1.76870479583740234375e+01) (17, 8.12929630279541015625e+00) (18, 3.30141115188598632812e+00) (19, 1.52997910976409912109e+00) (20, -1.62202632427215576172e+00) (21, -1.48425231933593750000e+03) (22, -2.92263269424438476562e+00) (18, 1.50000000000000000000e+03) (19, 1.50000000000000000000e+03) (20, -3.28328216552734375000e+02) (21, -5.71643920898437500000e+02) (22, 2.10364460945129394531e+00) (18, 1.10365409851074218750e+01) (19, 1.76004564762115478516e+00) (20, -1.30950450897216796875e+00) (21, -6.99483633041381835938e-01) (22, -9.65728700160980224609e-01) (18, 2.26503634452819824219e+00) (19, 2.09039592742919921875e+00) (20, -1.11790084838867187500e+00) (21, 1.67346286773681640625e+00) (22, -9.05837774276733398438e-01) (23, 5.88882350921630859375e+00) (24, 7.76117980480194091797e-01) (25, 3.39599728584289550781e+00) (26, 3.33684897422790527344e+00) (27, 1.60789799690246582031e+00) 
