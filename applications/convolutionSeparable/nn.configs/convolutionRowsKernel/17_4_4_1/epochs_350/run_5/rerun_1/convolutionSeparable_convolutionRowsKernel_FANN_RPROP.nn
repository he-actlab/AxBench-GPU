FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=18 5 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.59270219802856445312e+01) (1, 4.95429563522338867188e+00) (2, 4.23128414154052734375e+00) (3, -4.29892969131469726562e+00) (4, -1.78505325317382812500e+01) (5, 2.46716952323913574219e+00) (6, 1.82849061489105224609e+00) (7, 3.48833370208740234375e+00) (8, 7.41993141174316406250e+00) (9, 5.53449153900146484375e+00) (10, 5.60456895828247070312e+00) (11, 9.40096282958984375000e+00) (12, 6.16490697860717773438e+00) (13, 5.56078052520751953125e+00) (14, 5.61452245712280273438e+00) (15, 5.46082592010498046875e+00) (16, 6.20689296722412109375e+00) (17, 3.32435774803161621094e+00) (0, 7.87963271141052246094e-01) (1, 1.52670443058013916016e+00) (2, 1.10773241519927978516e+00) (3, 1.27895307540893554688e+00) (4, 1.04052436351776123047e+00) (5, -1.17965710163116455078e+00) (6, -1.10708761215209960938e+00) (7, -1.42836439609527587891e+00) (8, 4.12953853607177734375e-01) (9, 9.46140170097351074219e-01) (10, 1.27952980995178222656e+00) (11, 1.23271620273590087891e+00) (12, 1.31571197509765625000e+00) (13, 1.32111144065856933594e+00) (14, 9.66210186481475830078e-01) (15, 1.30389893054962158203e+00) (16, 1.07541060447692871094e+00) (17, -5.11828994750976562500e+00) (0, 2.51330089569091796875e+00) (1, -4.05338972806930541992e-01) (2, 5.60567080974578857422e-01) (3, 8.78460645675659179688e-01) (4, 1.25034940242767333984e+00) (5, -1.92507195472717285156e+00) (6, -1.04739022254943847656e+00) (7, -6.48844599723815917969e-01) (8, -2.23315978050231933594e+00) (9, 2.47881698608398437500e+00) (10, 5.21279096603393554688e-01) (11, 6.77055716514587402344e-01) (12, 3.60332727432250976562e-01) (13, 5.15775680541992187500e-01) (14, 2.04308748245239257812e+00) (15, 6.48084104061126708984e-01) (16, 1.06829655170440673828e+00) (17, -3.43219566345214843750e+00) (0, 1.54533648490905761719e+00) (1, 2.15975195169448852539e-01) (2, 5.32811343669891357422e-01) (3, 7.93992936611175537109e-01) (4, 9.69264984130859375000e-01) (5, 2.59091258049011230469e-01) (6, -7.16220140457153320312e-01) (7, 5.33540546894073486328e-01) (8, -6.00266337394714355469e-01) (9, 1.01630020141601562500e+00) (10, 4.01980012655258178711e-01) (11, 2.78870701789855957031e-01) (12, 1.93613976240158081055e-01) (13, 3.24497640132904052734e-01) (14, 7.28132426738739013672e-01) (15, 8.09453949332237243652e-02) (16, 1.18364465236663818359e+00) (17, -3.40088438987731933594e+00) (18, 1.13203644752502441406e+00) (19, 1.09317314147949218750e+02) (20, 6.92804412841796875000e+01) (21, 6.12860755920410156250e+01) (22, 9.75684046745300292969e-01) (18, -3.11115455627441406250e+00) (19, 5.22861957550048828125e+00) (20, 5.32642960548400878906e-01) (21, 6.00091278553009033203e-01) (22, -2.97336077690124511719e+00) (18, -8.94705593585968017578e-01) (19, 1.71361274719238281250e+01) (20, 2.24846410751342773438e+00) (21, 1.32342970371246337891e+00) (22, -8.86911273002624511719e-01) (18, -1.02038776874542236328e+00) (19, 5.43685626983642578125e+00) (20, 9.17003095149993896484e-01) (21, 7.56511807441711425781e-01) (22, -9.01106953620910644531e-01) (23, 1.06707727909088134766e+00) (24, 9.80010318756103515625e+00) (25, 2.79550075531005859375e+00) (26, 3.94663405418395996094e+00) (27, 9.73818182945251464844e-01) 
