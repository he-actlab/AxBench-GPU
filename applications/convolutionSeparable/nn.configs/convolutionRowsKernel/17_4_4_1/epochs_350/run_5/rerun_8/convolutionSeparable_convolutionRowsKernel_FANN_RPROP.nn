FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=18 5 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 8.38622331619262695312e-01) (1, 1.86617553234100341797e+00) (2, 2.79872626066207885742e-01) (3, 1.76134383678436279297e+00) (4, 5.16859591007232666016e-01) (5, -5.29076635837554931641e-01) (6, -1.42451155185699462891e+00) (7, -1.80851936340332031250e-01) (8, 1.92234292626380920410e-01) (9, 1.04103291034698486328e+00) (10, 1.70682108402252197266e+00) (11, 9.17986512184143066406e-01) (12, 1.56376636028289794922e+00) (13, 1.05047035217285156250e+00) (14, 1.11059367656707763672e+00) (15, 1.64594531059265136719e+00) (16, 1.64502608776092529297e+00) (17, -7.77399635314941406250e+00) (0, 1.26150822639465332031e+00) (1, 3.81408977508544921875e+00) (2, 5.88911628723144531250e+00) (3, 3.87784218788146972656e+00) (4, 3.72203779220581054688e+00) (5, 1.50000000000000000000e+03) (6, 1.39866209030151367188e+01) (7, 2.84267139434814453125e+01) (8, 4.31194925308227539062e+00) (9, 6.19712829589843750000e-01) (10, 4.60155963897705078125e+00) (11, 1.24835639953613281250e+02) (12, 3.41664195060729980469e+00) (13, 2.15305495262145996094e+00) (14, 1.49004721641540527344e+00) (15, 1.50000000000000000000e+03) (16, 3.81262803077697753906e+00) (17, 1.75290393829345703125e+00) (0, -4.59728145599365234375e+00) (1, -2.54547786712646484375e+00) (2, -6.21527719497680664062e+00) (3, -5.70745420455932617188e+00) (4, -3.54164242744445800781e+00) (5, 1.13887090682983398438e+01) (6, 7.35421800613403320312e+00) (7, 1.17034149169921875000e+01) (8, 3.95053625106811523438e+00) (9, -5.19411659240722656250e+00) (10, -5.03398466110229492188e+00) (11, -1.73603880405426025391e+00) (12, -5.10264444351196289062e+00) (13, -5.29860782623291015625e+00) (14, 9.51678872108459472656e-01) (15, -4.42384481430053710938e+00) (16, 8.48642253875732421875e+00) (17, 1.93094098567962646484e+00) (0, 2.03315973281860351562e+00) (1, 2.41999769210815429688e+00) (2, 2.35356903076171875000e+00) (3, 1.35754942893981933594e+00) (4, 1.59378600120544433594e+00) (5, -1.14709712564945220947e-01) (6, -2.89788079261779785156e+00) (7, -2.04460471868515014648e-01) (8, 2.49656528234481811523e-01) (9, 2.00948405265808105469e+00) (10, 1.00535881519317626953e+00) (11, 1.95911681652069091797e+00) (12, 2.32871913909912109375e+00) (13, 2.27486753463745117188e+00) (14, 2.90755558013916015625e+00) (15, 2.14862823486328125000e+00) (16, 3.03459119796752929688e+00) (17, -6.96327209472656250000e+00) (18, 1.50000000000000000000e+03) (19, 1.25001561641693115234e+00) (20, -1.15427749633789062500e+02) (21, 1.49999975585937500000e+03) (22, 1.15711987018585205078e+00) (18, 2.85197520256042480469e+00) (19, -1.03207433223724365234e+00) (20, -3.79180043935775756836e-01) (21, 1.95274555683135986328e+00) (22, -1.16143846511840820312e+00) (18, 1.50000000000000000000e+03) (19, 1.24666893482208251953e+00) (20, -1.15460548400878906250e+02) (21, 1.49999975585937500000e+03) (22, 1.26347649097442626953e+00) (18, 1.50000000000000000000e+03) (19, 6.65952205657958984375e-01) (20, -1.22684944152832031250e+02) (21, 1.49912023925781250000e+03) (22, 7.59435951709747314453e-01) (23, 7.12692618370056152344e-01) (24, 1.07875280380249023438e+01) (25, 7.54866659641265869141e-01) (26, 7.50510811805725097656e-01) (27, 1.04866766929626464844e+00) 
