FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=18 5 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.49999902343750000000e+03) (1, 1.50000000000000000000e+03) (2, 1.33306982421875000000e+03) (3, 7.68106262207031250000e+02) (4, 7.60740539550781250000e+02) (5, 1.50000000000000000000e+03) (6, 1.50000000000000000000e+03) (7, 1.50000000000000000000e+03) (8, 8.11909790039062500000e+01) (9, 5.08139251708984375000e+02) (10, 7.63027526855468750000e+02) (11, 1.49999536132812500000e+03) (12, 7.24286804199218750000e+02) (13, 9.70967041015625000000e+02) (14, 7.64476013183593750000e+02) (15, 7.13184265136718750000e+02) (16, 5.02424560546875000000e+02) (17, 7.88197708129882812500e+00) (0, 1.49999902343750000000e+03) (1, 1.50000000000000000000e+03) (2, 1.13956005859375000000e+03) (3, 7.67284545898437500000e+02) (4, 7.60858520507812500000e+02) (5, 1.50000000000000000000e+03) (6, 1.50000000000000000000e+03) (7, 1.50000000000000000000e+03) (8, 8.13101501464843750000e+01) (9, 5.08059051513671875000e+02) (10, 7.63034729003906250000e+02) (11, 1.49999536132812500000e+03) (12, 7.24110961914062500000e+02) (13, 9.71111877441406250000e+02) (14, 7.64520812988281250000e+02) (15, 7.13053527832031250000e+02) (16, 5.02388549804687500000e+02) (17, 7.79928016662597656250e+00) (0, 1.49999902343750000000e+03) (1, 1.50000000000000000000e+03) (2, 1.11255725097656250000e+03) (3, 7.67222167968750000000e+02) (4, 7.60739868164062500000e+02) (5, 1.50000000000000000000e+03) (6, 1.50000000000000000000e+03) (7, 1.50000000000000000000e+03) (8, 8.15460739135742187500e+01) (9, 5.08126159667968750000e+02) (10, 7.62878417968750000000e+02) (11, 1.49999536132812500000e+03) (12, 7.26278076171875000000e+02) (13, 9.70964904785156250000e+02) (14, 7.64599670410156250000e+02) (15, 7.12867492675781250000e+02) (16, 5.02541870117187500000e+02) (17, 7.79608726501464843750e+00) (0, 1.94025182723999023438e+00) (1, 1.93014562129974365234e+00) (2, 1.76175332069396972656e+00) (3, 2.02182745933532714844e+00) (4, 1.37936091423034667969e+00) (5, -1.33572649955749511719e+00) (6, -2.25982594490051269531e+00) (7, -1.45441341400146484375e+00) (8, 1.14557489752769470215e-01) (9, 1.99746370315551757812e+00) (10, 1.74152719974517822266e+00) (11, 1.97525584697723388672e+00) (12, 1.83518278598785400391e+00) (13, 2.03076505661010742188e+00) (14, 1.52652907371520996094e+00) (15, 1.87207376956939697266e+00) (16, 1.80130434036254882812e+00) (17, -6.63810920715332031250e+00) (18, 1.19217967987060546875e+00) (19, 1.14430463314056396484e+00) (20, 1.13566362857818603516e+00) (21, 1.50000000000000000000e+03) (22, 1.09623658657073974609e+00) (18, -2.67705273628234863281e+00) (19, -2.63925576210021972656e+00) (20, -2.60344123840332031250e+00) (21, 1.04897031784057617188e+01) (22, -2.68288326263427734375e+00) (18, -4.99572396278381347656e-01) (19, -5.03105998039245605469e-01) (20, -5.86086928844451904297e-01) (21, 1.00833044052124023438e+01) (22, -4.07628566026687622070e-01) (18, 1.15457642078399658203e+00) (19, 1.17909884452819824219e+00) (20, 1.19354367256164550781e+00) (21, 1.50000000000000000000e+03) (22, 1.18408703804016113281e+00) (23, 1.18799471855163574219e+00) (24, 9.54276943206787109375e+00) (25, 3.77352595329284667969e+00) (26, 1.20468783378601074219e+00) (27, 1.12412607669830322266e+00) 
