FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=18 5 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -8.84273529052734375000e+00) (1, 6.64080715179443359375e+00) (2, 8.13778018951416015625e+00) (3, 6.03190326690673828125e+00) (4, 1.17625246047973632812e+01) (5, 2.22582035064697265625e+01) (6, 1.56801824569702148438e+01) (7, 1.61849117279052734375e+01) (8, 6.79731798171997070312e+00) (9, 4.96801137924194335938e+00) (10, 4.12782049179077148438e+00) (11, 3.74106144905090332031e+00) (12, -1.08031644821166992188e+01) (13, 4.86232900619506835938e+00) (14, 5.38283252716064453125e+00) (15, -8.69588088989257812500e+00) (16, 5.97874832153320312500e+00) (17, 1.64339578151702880859e+00) (0, 6.35415375232696533203e-01) (1, 5.84965765476226806641e-01) (2, 4.75134998559951782227e-01) (3, 5.57669043540954589844e-01) (4, 5.23398876190185546875e-01) (5, 1.41399651765823364258e-01) (6, -2.65547811985015869141e-01) (7, -2.38625884056091308594e-01) (8, 4.66716289520263671875e-01) (9, 7.65197336673736572266e-01) (10, 7.40434706211090087891e-01) (11, 1.10728752613067626953e+00) (12, 6.17227911949157714844e-01) (13, 5.74190199375152587891e-01) (14, 5.97254097461700439453e-01) (15, 6.80561900138854980469e-01) (16, 7.79502093791961669922e-01) (17, -3.86901593208312988281e+00) (0, 5.32910943031311035156e-01) (1, 5.51937699317932128906e-01) (2, 4.78250354528427124023e-01) (3, 5.99091172218322753906e-01) (4, 6.25605344772338867188e-01) (5, -1.14116244018077850342e-01) (6, -1.45516261458396911621e-01) (7, -3.43456268310546875000e-01) (8, 4.11272674798965454102e-01) (9, 1.21429967880249023438e+00) (10, 2.16530978679656982422e-01) (11, 6.83223843574523925781e-01) (12, 6.43266558647155761719e-01) (13, 5.12593686580657958984e-01) (14, 4.56606149673461914062e-01) (15, 5.95991611480712890625e-01) (16, 8.72928678989410400391e-01) (17, -4.02543973922729492188e+00) (0, -1.59012126922607421875e+00) (1, -1.32048785686492919922e+00) (2, -1.63318419456481933594e+00) (3, -1.52823042869567871094e+00) (4, -1.56012904644012451172e+00) (5, 3.49108624458312988281e+00) (6, 2.47677445411682128906e+00) (7, 2.66865205764770507812e+00) (8, 9.34678673744201660156e-01) (9, 3.50459873676300048828e-01) (10, -2.05009460449218750000e+00) (11, -5.53314387798309326172e-01) (12, -1.37139463424682617188e+00) (13, -1.54822027683258056641e+00) (14, -1.57165050506591796875e+00) (15, -1.79186046123504638672e+00) (16, -4.90787804126739501953e-01) (17, 2.15131521224975585938e+00) (18, 1.44302940368652343750e+00) (19, 1.72105209350585937500e+02) (20, 1.20464013671875000000e+03) (21, -1.62810382843017578125e+01) (22, 1.56359124183654785156e+00) (18, -1.20565259456634521484e+00) (19, 9.51528191566467285156e-01) (20, 2.50588870048522949219e+00) (21, -3.45244836807250976562e+00) (22, -1.18971920013427734375e+00) (18, 7.28456854820251464844e-01) (19, 3.19325790405273437500e+01) (20, 7.40034713745117187500e+01) (21, -2.42331676483154296875e+01) (22, 6.60607874393463134766e-01) (18, -7.75608837604522705078e-01) (19, 3.51953721046447753906e+00) (20, 3.67468786239624023438e+00) (21, -1.06301534175872802734e+00) (22, -6.66822016239166259766e-01) (23, 1.51467716693878173828e+00) (24, 7.97016191482543945312e+00) (25, 8.90222966670989990234e-01) (26, 4.87088441848754882812e+00) (27, 1.64525663852691650391e+00) 
