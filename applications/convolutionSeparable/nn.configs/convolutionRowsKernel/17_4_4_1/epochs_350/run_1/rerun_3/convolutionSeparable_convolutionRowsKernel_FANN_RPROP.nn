FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=18 5 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 4.41707229614257812500e+01) (1, 3.23608283996582031250e+01) (2, 2.74190635681152343750e+01) (3, 1.31554211425781250000e+03) (4, 3.84298973083496093750e+01) (5, 7.54717590332031250000e+02) (6, 5.18578674316406250000e+02) (7, 1.45102343750000000000e+03) (8, 2.14913234710693359375e+01) (9, 1.67242870330810546875e+01) (10, 2.87133674621582031250e+01) (11, 3.27107582092285156250e+01) (12, 3.27390975952148437500e+01) (13, 3.13428096771240234375e+01) (14, 3.28826408386230468750e+01) (15, 3.23911628723144531250e+01) (16, 2.56454715728759765625e+01) (17, 1.90212321281433105469e+00) (0, 3.50799217224121093750e+01) (1, 3.22818374633789062500e+01) (2, 2.75879554748535156250e+01) (3, 1.32537683105468750000e+03) (4, 3.84980812072753906250e+01) (5, 1.03877856445312500000e+03) (6, 5.18622314453125000000e+02) (7, 1.45101940917968750000e+03) (8, 2.04770507812500000000e+01) (9, 1.67510280609130859375e+01) (10, 2.87765274047851562500e+01) (11, 3.26476325988769531250e+01) (12, 3.25924873352050781250e+01) (13, 3.13078098297119140625e+01) (14, 3.29026832580566406250e+01) (15, 3.22152824401855468750e+01) (16, 2.64167556762695312500e+01) (17, 1.85777032375335693359e+00) (0, 9.79234874248504638672e-01) (1, 8.82986545562744140625e-01) (2, 7.78902053833007812500e-01) (3, 2.28409004211425781250e+00) (4, 5.11899471282958984375e-01) (5, -3.36365997791290283203e-01) (6, -1.78199446201324462891e+00) (7, -1.35096573829650878906e+00) (8, 3.94993394613265991211e-01) (9, 1.13102126121520996094e+00) (10, 1.15416550636291503906e+00) (11, 9.57664787769317626953e-01) (12, 8.62845659255981445312e-01) (13, 9.58251774311065673828e-01) (14, 6.38452529907226562500e-01) (15, 9.43420410156250000000e-01) (16, 1.05600607395172119141e+00) (17, -4.18669509887695312500e+00) (0, 1.19716286659240722656e+00) (1, 1.29179608821868896484e+00) (2, 7.45713114738464355469e-01) (3, -3.91218215227127075195e-01) (4, 7.15384721755981445312e-01) (5, -1.12605834007263183594e+00) (6, -2.06170395016670227051e-01) (7, -3.85145545005798339844e-01) (8, -2.15098604559898376465e-01) (9, 3.74037176370620727539e-01) (10, 9.00061309337615966797e-01) (11, 1.01009452342987060547e+00) (12, 1.16093075275421142578e+00) (13, 1.28889787197113037109e+00) (14, 1.43076241016387939453e+00) (15, 1.42042219638824462891e+00) (16, 6.90497219562530517578e-01) (17, -4.82309675216674804688e+00) (18, 9.73780274391174316406e-01) (19, 9.73357319831848144531e-01) (20, 1.49774450683593750000e+03) (21, 1.50000000000000000000e+03) (22, 9.70558524131774902344e-01) (18, -1.13741064071655273438e+00) (19, -1.18917500972747802734e+00) (20, 3.13388085365295410156e+00) (21, 1.75762927532196044922e+00) (22, -1.17722427845001220703e+00) (18, 1.04357421398162841797e+00) (19, 9.28792476654052734375e-01) (20, 1.49774450683593750000e+03) (21, 1.50000000000000000000e+03) (22, 9.38670098781585693359e-01) (18, -8.30017805099487304688e-01) (19, -8.15783917903900146484e-01) (20, 8.38649368286132812500e+00) (21, 7.85097360610961914062e+00) (22, -7.24917292594909667969e-01) (23, 1.03566157817840576172e+00) (24, 8.98651599884033203125e+00) (25, 1.04948127269744873047e+00) (26, 3.35891199111938476562e+00) (27, 9.64778304100036621094e-01) 
