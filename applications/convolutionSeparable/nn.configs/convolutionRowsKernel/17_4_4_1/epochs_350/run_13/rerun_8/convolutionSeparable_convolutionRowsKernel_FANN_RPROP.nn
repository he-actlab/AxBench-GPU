FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=18 5 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 9.93675053119659423828e-01) (1, 1.01596772670745849609e+00) (2, 8.65383446216583251953e-01) (3, 6.57986640930175781250e-01) (4, 4.58444029092788696289e-01) (5, -4.71542000770568847656e-01) (6, -9.65546369552612304688e-02) (7, -9.96055230498313903809e-02) (8, 3.75117272138595581055e-01) (9, 6.93434298038482666016e-01) (10, 1.11884725093841552734e+00) (11, 7.53294467926025390625e-01) (12, 7.64153361320495605469e-01) (13, 1.00125443935394287109e+00) (14, 8.77689421176910400391e-01) (15, 6.70411944389343261719e-01) (16, 9.24515843391418457031e-01) (17, -4.40224361419677734375e+00) (0, 7.79789507389068603516e-01) (1, 5.80773770809173583984e-01) (2, 5.65940141677856445312e-01) (3, 5.51160991191864013672e-01) (4, 5.67106842994689941406e-01) (5, -8.18036437034606933594e-01) (6, -3.75779002904891967773e-01) (7, -2.26560577750205993652e-01) (8, 1.67308807373046875000e-01) (9, 8.73936295509338378906e-01) (10, 3.65136176347732543945e-01) (11, 1.95889204740524291992e-01) (12, 7.76057898998260498047e-01) (13, 6.59847855567932128906e-01) (14, 7.05623745918273925781e-01) (15, 3.85213702917098999023e-01) (16, 5.82320094108581542969e-01) (17, -4.32659530639648437500e+00) (0, 5.50949752330780029297e-01) (1, 6.29859447479248046875e-01) (2, 6.67755842208862304688e-01) (3, 9.88474071025848388672e-01) (4, 8.85642170906066894531e-01) (5, -8.43036174774169921875e-01) (6, -1.27172279357910156250e+00) (7, -1.08321642875671386719e+00) (8, -1.51402816176414489746e-01) (9, 6.39083623886108398438e-01) (10, 6.61475002765655517578e-01) (11, 1.07456660270690917969e+00) (12, 5.20188927650451660156e-01) (13, 7.26009070873260498047e-01) (14, 5.08879184722900390625e-01) (15, 9.94385778903961181641e-01) (16, 6.42369151115417480469e-01) (17, -3.57504725456237792969e+00) (0, 7.55406916141510009766e-01) (1, 6.79047822952270507812e-01) (2, 7.60416269302368164062e-01) (3, 4.78029012680053710938e-01) (4, 5.72707414627075195312e-01) (5, -3.34027707576751708984e-01) (6, -5.08824467658996582031e-01) (7, -5.75338482856750488281e-01) (8, -1.42586216330528259277e-01) (9, 5.20664155483245849609e-01) (10, 9.11495447158813476562e-01) (11, 4.20854866504669189453e-01) (12, 7.59742677211761474609e-01) (13, 6.96830213069915771484e-01) (14, 7.11246788501739501953e-01) (15, 6.40921354293823242188e-01) (16, 6.40589952468872070312e-01) (17, -3.13075590133666992188e+00) (18, 3.67476195096969604492e-01) (19, 3.77537631988525390625e+00) (20, 1.88472270965576171875e+00) (21, 1.73405897617340087891e+00) (22, -4.03722429275512695312e+00) (18, 1.06996178627014160156e-01) (19, 8.04008901119232177734e-01) (20, 1.62041878700256347656e+00) (21, 1.04603219032287597656e+00) (22, -1.72321760654449462891e+00) (18, 1.31557798385620117188e+00) (19, 8.45070660114288330078e-01) (20, 3.04461598396301269531e+00) (21, 1.72369599342346191406e+00) (22, -1.53859353065490722656e+00) (18, 1.41166627407073974609e+00) (19, 4.94460678100585937500e+00) (20, 1.13878231048583984375e+01) (21, 2.62006878852844238281e+00) (22, -1.84038329124450683594e+00) (23, 5.33391380310058593750e+00) (24, 3.56251120567321777344e+00) (25, 3.56087112426757812500e+00) (26, 3.63600587844848632812e+00) (27, 4.39898967742919921875e-01) 
