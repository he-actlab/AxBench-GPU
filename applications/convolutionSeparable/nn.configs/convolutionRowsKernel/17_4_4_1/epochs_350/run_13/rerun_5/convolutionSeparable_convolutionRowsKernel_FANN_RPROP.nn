FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=18 5 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 8.47572028636932373047e-01) (1, 8.46586883068084716797e-01) (2, 8.44572484493255615234e-01) (3, 1.11304354667663574219e+00) (4, 7.33880817890167236328e-01) (5, -4.79506313800811767578e-01) (6, -6.89873635768890380859e-01) (7, -5.63682377338409423828e-01) (8, 2.05849885940551757812e-01) (9, 7.76063024997711181641e-01) (10, 9.46536719799041748047e-01) (11, 8.36284399032592773438e-01) (12, 8.11806261539459228516e-01) (13, 6.44666850566864013672e-01) (14, 6.17312312126159667969e-01) (15, 6.79615795612335205078e-01) (16, 7.91832625865936279297e-01) (17, -3.83772587776184082031e+00) (0, 3.94290059804916381836e-01) (1, 3.99896323680877685547e-01) (2, 3.85623544454574584961e-01) (3, 4.41468685865402221680e-01) (4, 3.79173338413238525391e-01) (5, -6.68445229530334472656e-02) (6, -6.70582652091979980469e-01) (7, -1.31343102455139160156e+00) (8, 1.33311688899993896484e-01) (9, 4.99261707067489624023e-01) (10, 3.87070804834365844727e-01) (11, 3.85987162590026855469e-01) (12, 5.29466271400451660156e-01) (13, 4.88090872764587402344e-01) (14, 5.75773119926452636719e-01) (15, 5.40952920913696289062e-01) (16, 6.18953168392181396484e-01) (17, -2.96455669403076171875e+00) (0, 7.55832135677337646484e-01) (1, 5.76834678649902343750e-01) (2, 6.80638313293457031250e-01) (3, 4.73671823740005493164e-01) (4, 7.64689862728118896484e-01) (5, -4.80981945991516113281e-01) (6, -6.85553371906280517578e-01) (7, -2.49638170003890991211e-01) (8, -6.49388968944549560547e-01) (9, 6.94167137145996093750e-01) (10, 6.83276474475860595703e-01) (11, 5.66861152648925781250e-01) (12, 8.70482981204986572266e-01) (13, 9.00827586650848388672e-01) (14, 9.97528374195098876953e-01) (15, 8.98273706436157226562e-01) (16, 7.60030448436737060547e-01) (17, -5.21393775939941406250e+00) (0, 9.65823173522949218750e-01) (1, 8.21094810962677001953e-01) (2, 8.79396736621856689453e-01) (3, 6.84662222862243652344e-01) (4, 7.33900725841522216797e-01) (5, -1.72044789791107177734e+00) (6, -7.77586936950683593750e-01) (7, -8.36239099502563476562e-01) (8, 2.96090334653854370117e-01) (9, 6.72984838485717773438e-01) (10, 8.39590430259704589844e-01) (11, 6.89561903476715087891e-01) (12, 9.14110600948333740234e-01) (13, 6.83402001857757568359e-01) (14, 7.70663738250732421875e-01) (15, 6.41804039478302001953e-01) (16, 5.88493764400482177734e-01) (17, -4.61436271667480468750e+00) (18, 1.62323617935180664062e+00) (19, 1.42812597751617431641e+00) (20, 1.65481781959533691406e+00) (21, 1.21565270423889160156e+00) (22, -2.04313898086547851562e+00) (18, 3.61530137062072753906e+00) (19, 3.64956355094909667969e+00) (20, 2.22075462341308593750e+01) (21, 3.03199863433837890625e+01) (22, -3.84243607521057128906e+00) (18, 1.66800880432128906250e+00) (19, 1.71022903919219970703e+00) (20, 1.56604361534118652344e+00) (21, 1.22218275070190429688e+00) (22, -2.25203108787536621094e+00) (18, 1.49305355548858642578e+00) (19, 8.56291174888610839844e-01) (20, 1.69692432880401611328e+00) (21, 1.22348785400390625000e+00) (22, -1.62363290786743164062e+00) (23, 3.81739354133605957031e+00) (24, 2.39375567436218261719e+00) (25, 3.89232707023620605469e+00) (26, 3.80706310272216796875e+00) (27, 1.69211399555206298828e+00) 
