FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=18 5 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 8.19292128086090087891e-01) (1, 7.28755414485931396484e-01) (2, 8.89106154441833496094e-01) (3, 1.20849120616912841797e+00) (4, 8.71217608451843261719e-01) (5, -1.71417665481567382812e+00) (6, -6.17478311061859130859e-01) (7, -1.75952792167663574219e+00) (8, -1.87809944152832031250e-01) (9, 6.27559721469879150391e-01) (10, 8.37196469306945800781e-01) (11, 7.76227355003356933594e-01) (12, 2.17633292078971862793e-01) (13, 1.07724976539611816406e+00) (14, 7.55860149860382080078e-01) (15, 1.02570533752441406250e+00) (16, 4.42049503326416015625e-01) (17, -4.68730735778808593750e+00) (0, 4.66563582420349121094e-01) (1, 1.00084817409515380859e+00) (2, 5.53777694702148437500e-01) (3, 4.85264807939529418945e-01) (4, 4.99086290597915649414e-01) (5, -6.00448668003082275391e-01) (6, -9.03448522090911865234e-01) (7, -9.66865867376327514648e-02) (8, 1.78703263401985168457e-01) (9, 7.22463488578796386719e-01) (10, 8.41869354248046875000e-01) (11, 8.14309060573577880859e-01) (12, 4.90466535091400146484e-01) (13, 3.99779200553894042969e-01) (14, 6.34893238544464111328e-01) (15, 8.41860234737396240234e-01) (16, 9.67167139053344726562e-01) (17, -3.29172229766845703125e+00) (0, 2.41163539886474609375e+00) (1, 1.89700102806091308594e+00) (2, 1.52337408065795898438e+00) (3, 2.04949069023132324219e+00) (4, 2.20519232749938964844e+00) (5, -1.39910805225372314453e+00) (6, -3.19422554969787597656e+00) (7, -2.05013513565063476562e+00) (8, 9.43586677312850952148e-02) (9, 1.82573556900024414062e+00) (10, 1.19901514053344726562e+00) (11, 2.51203751564025878906e+00) (12, 2.02828359603881835938e+00) (13, 1.35489487648010253906e+00) (14, 2.28879213333129882812e+00) (15, 1.35915529727935791016e+00) (16, 1.91606295108795166016e+00) (17, -3.66814517974853515625e+00) (0, 8.33631575107574462891e-01) (1, 1.55873566865921020508e-01) (2, 8.08889746665954589844e-01) (3, 5.44067263603210449219e-01) (4, 5.26559948921203613281e-01) (5, -4.60378490388393402100e-02) (6, -2.23441600799560546875e-01) (7, -5.38849592208862304688e-01) (8, -3.29540520906448364258e-02) (9, 5.85725665092468261719e-01) (10, 6.58830642700195312500e-01) (11, 4.99802857637405395508e-01) (12, 1.01128280162811279297e+00) (13, 1.02216494083404541016e+00) (14, 5.11390686035156250000e-01) (15, 4.33165609836578369141e-01) (16, 5.02760350704193115234e-01) (17, -3.93658137321472167969e+00) (18, 1.58563280105590820312e+00) (19, 1.18910920619964599609e+00) (20, 1.17334270477294921875e+00) (21, 1.26529216766357421875e+00) (22, -2.48799633979797363281e+00) (18, 1.63010179996490478516e+00) (19, 1.14752292633056640625e+00) (20, 1.22919785976409912109e+00) (21, 1.26602077484130859375e+00) (22, -2.57904267311096191406e+00) (18, 1.51157152652740478516e+00) (19, 1.09822893142700195312e+00) (20, 1.21729528903961181641e+00) (21, 9.91634249687194824219e-01) (22, -2.24499368667602539062e+00) (18, 1.55135238170623779297e+00) (19, 9.93722796440124511719e-01) (20, 1.40208292007446289062e+00) (21, 1.00027549266815185547e+00) (22, -2.38730406761169433594e+00) (23, 3.69350433349609375000e+00) (24, 5.26933050155639648438e+00) (25, 3.53913903236389160156e+00) (26, 3.56234073638916015625e+00) (27, 1.18954956531524658203e+00) 
