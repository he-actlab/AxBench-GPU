FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=18 5 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 7.71681547164916992188e-01) (1, 1.48834013938903808594e+00) (2, 1.51544654369354248047e+00) (3, 7.60938107967376708984e-01) (4, 1.72088563442230224609e+00) (5, -8.91823887825012207031e-01) (6, -1.09654319286346435547e+00) (7, -1.21793854236602783203e+00) (8, -2.20482032746076583862e-02) (9, 7.98530578613281250000e-01) (10, 9.34572935104370117188e-01) (11, 1.09161949157714843750e+00) (12, 9.76788699626922607422e-01) (13, 9.41504299640655517578e-01) (14, 1.04763317108154296875e+00) (15, 9.30508196353912353516e-01) (16, 1.04236257076263427734e+00) (17, -2.66772556304931640625e+00) (0, 1.06479310989379882812e+00) (1, 1.52298545837402343750e+00) (2, 1.33871650695800781250e+00) (3, 1.02053892612457275391e+00) (4, 8.58479321002960205078e-01) (5, -1.20801687240600585938e+00) (6, -9.96582508087158203125e-01) (7, -1.18537890911102294922e+00) (8, -2.04033315181732177734e-01) (9, 1.39338588714599609375e+00) (10, 1.39107203483581542969e+00) (11, 6.26806616783142089844e-01) (12, 1.38871574401855468750e+00) (13, 1.60573148727416992188e+00) (14, 1.10279941558837890625e+00) (15, 1.30121791362762451172e+00) (16, 6.64321720600128173828e-01) (17, -2.62630391120910644531e+00) (0, 5.04354536533355712891e-01) (1, 7.84163177013397216797e-02) (2, -6.01084768772125244141e-01) (3, 2.82261461019515991211e-01) (4, 4.63585227727890014648e-01) (5, -1.82122647762298583984e+00) (6, -3.78221422433853149414e-01) (7, -6.28835260868072509766e-01) (8, 1.50951117277145385742e-01) (9, 5.24842023849487304688e-01) (10, 1.11254537105560302734e+00) (11, 1.06611979007720947266e+00) (12, 3.56230348348617553711e-01) (13, 2.43354380130767822266e-01) (14, 3.74752759933471679688e-01) (15, 9.00147259235382080078e-01) (16, 1.14854907989501953125e+00) (17, -2.32655930519104003906e+00) (0, 9.61882472038269042969e-01) (1, 8.20300877094268798828e-01) (2, 1.09546339511871337891e+00) (3, 1.03276669979095458984e+00) (4, 7.07946538925170898438e-01) (5, -4.03915613889694213867e-01) (6, -1.12549149990081787109e+00) (7, -6.98370754718780517578e-01) (8, -6.65202066302299499512e-02) (9, 7.76434063911437988281e-01) (10, 7.86209642887115478516e-01) (11, 8.25444459915161132812e-01) (12, 8.91595721244812011719e-01) (13, 8.79375219345092773438e-01) (14, 8.81668388843536376953e-01) (15, 7.83154428005218505859e-01) (16, 7.78275668621063232422e-01) (17, -6.22255611419677734375e+00) (18, 1.11984801292419433594e+00) (19, 1.14171159267425537109e+00) (20, 5.66868484020233154297e-01) (21, 2.97684621810913085938e+00) (22, -2.21132230758666992188e+00) (18, 9.13520991802215576172e-01) (19, 7.78514325618743896484e-01) (20, 5.54978489875793457031e-01) (21, 3.74186158180236816406e+00) (22, -2.29935908317565917969e+00) (18, 1.07766008377075195312e+00) (19, 1.13457393646240234375e+00) (20, 4.96638923883438110352e-01) (21, 2.99214887619018554688e+00) (22, -2.17538189888000488281e+00) (18, 7.88625061511993408203e-01) (19, 8.84594023227691650391e-01) (20, 4.95264589786529541016e-01) (21, 3.78557252883911132812e+00) (22, -2.24688339233398437500e+00) (23, 4.45744419097900390625e+00) (24, 3.66205310821533203125e+00) (25, 4.58910369873046875000e+00) (26, 3.14494848251342773438e+00) (27, 5.93637943267822265625e-01) 
