FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=18 5 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 6.04470789432525634766e-01) (1, 7.43603825569152832031e-01) (2, 8.34436178207397460938e-01) (3, 7.90892124176025390625e-01) (4, 7.15392827987670898438e-01) (5, -1.15588462352752685547e+00) (6, -1.31460404396057128906e+00) (7, -3.50283980369567871094e-01) (8, 2.05040559172630310059e-01) (9, 5.39955377578735351562e-01) (10, 6.02279722690582275391e-01) (11, 6.83000385761260986328e-01) (12, 7.57532596588134765625e-01) (13, 6.54786765575408935547e-01) (14, 6.12867295742034912109e-01) (15, 8.73286306858062744141e-01) (16, 5.87397933006286621094e-01) (17, -4.11074590682983398438e+00) (0, 8.21368098258972167969e-01) (1, 7.60666668415069580078e-01) (2, 7.66395032405853271484e-01) (3, 9.80055391788482666016e-01) (4, 1.01506674289703369141e+00) (5, -4.64536786079406738281e-01) (6, -4.48745459318161010742e-01) (7, -5.82522034645080566406e-01) (8, 2.73801386356353759766e-01) (9, 1.73799383640289306641e+00) (10, 9.41483914852142333984e-01) (11, 8.82124066352844238281e-01) (12, 8.08679044246673583984e-01) (13, 6.87278330326080322266e-01) (14, 1.17843890190124511719e+00) (15, 8.73505413532257080078e-01) (16, 1.26760673522949218750e+00) (17, -3.35217905044555664062e+00) (0, 7.55450427532196044922e-01) (1, 8.41915071010589599609e-01) (2, 4.45410162210464477539e-01) (3, 8.64212334156036376953e-01) (4, 4.18577373027801513672e-01) (5, -3.17634612321853637695e-01) (6, -4.65683966875076293945e-01) (7, -1.33925056457519531250e+00) (8, -5.22661924362182617188e-01) (9, 5.18455624580383300781e-01) (10, 5.28903126716613769531e-01) (11, 6.60490334033966064453e-01) (12, 6.15340948104858398438e-01) (13, 7.13720381259918212891e-01) (14, 6.33329153060913085938e-01) (15, 5.89240491390228271484e-01) (16, 5.36509335041046142578e-01) (17, -3.57600235939025878906e+00) (0, 3.99223089218139648438e-01) (1, 4.23009872436523437500e-01) (2, 4.30503308773040771484e-01) (3, 3.46505075693130493164e-01) (4, 6.66669428348541259766e-01) (5, -1.12170243263244628906e+00) (6, -5.26475429534912109375e-01) (7, -1.98148891329765319824e-01) (8, -6.44035562872886657715e-02) (9, 4.55145508050918579102e-01) (10, 7.81464755535125732422e-01) (11, 6.25126600265502929688e-01) (12, 9.43586826324462890625e-01) (13, 5.12858152389526367188e-01) (14, 6.38137400150299072266e-01) (15, 4.10428434610366821289e-01) (16, 5.03555536270141601562e-01) (17, -2.68643450736999511719e+00) (18, 2.19796848297119140625e+00) (19, 1.48727059364318847656e+00) (20, 2.40271162986755371094e+00) (21, 5.31459033489227294922e-01) (22, -2.00494098663330078125e+00) (18, 1.44191002845764160156e+00) (19, 1.38072538375854492188e+00) (20, 1.32748425006866455078e+00) (21, 5.86944818496704101562e-01) (22, -2.02223467826843261719e+00) (18, 1.48712694644927978516e+00) (19, 1.31086206436157226562e+00) (20, 1.37511825561523437500e+00) (21, 6.41522765159606933594e-01) (22, -1.80901467800140380859e+00) (18, 1.56338393688201904297e+00) (19, 1.03884673118591308594e+00) (20, 1.52944195270538330078e+00) (21, 5.98430573940277099609e-01) (22, -2.09926033020019531250e+00) (23, 3.96209597587585449219e+00) (24, 3.41264796257019042969e+00) (25, 3.32541537284851074219e+00) (26, 3.60047674179077148438e+00) (27, 1.28946709632873535156e+00) 
