FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=18 5 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 9.78400647640228271484e-01) (1, 1.05156040191650390625e+00) (2, 7.74288952350616455078e-01) (3, 1.24616563320159912109e+00) (4, 9.06435310840606689453e-01) (5, -8.82751286029815673828e-01) (6, -2.81627625226974487305e-01) (7, -1.51530802249908447266e+00) (8, 2.36928358674049377441e-01) (9, 6.23048305511474609375e-01) (10, 1.02284598350524902344e+00) (11, 1.21254992485046386719e+00) (12, 1.18804383277893066406e+00) (13, 5.61015605926513671875e-01) (14, 7.40507006645202636719e-01) (15, 1.24929893016815185547e+00) (16, 9.14795279502868652344e-01) (17, -5.66309738159179687500e+00) (0, 1.47250442504882812500e+01) (1, 3.13659610748291015625e+01) (2, 1.40276279449462890625e+01) (3, 1.31844625473022460938e+01) (4, 7.20657587051391601562e+00) (5, 6.08378410339355468750e+01) (6, 7.68046035766601562500e+01) (7, 9.02595443725585937500e+01) (8, 3.15591549873352050781e+00) (9, 5.12900209426879882812e+00) (10, 1.06048917770385742188e+00) (11, 6.30980491638183593750e+00) (12, 6.50339889526367187500e+00) (13, -8.55413019657135009766e-01) (14, 5.15499651432037353516e-01) (15, 8.80346179008483886719e-01) (16, -1.59192514419555664062e+01) (17, 1.87926483154296875000e+00) (0, 7.07834362983703613281e-01) (1, 1.28597903251647949219e+00) (2, 1.09524857997894287109e+00) (3, 8.88222634792327880859e-01) (4, 1.22019171714782714844e+00) (5, -1.14157164096832275391e+00) (6, -2.60676741600036621094e+00) (7, -4.22307014465332031250e-01) (8, -2.61456798762083053589e-02) (9, 1.18640136718750000000e+00) (10, 1.13981413841247558594e+00) (11, 6.01134955883026123047e-01) (12, 1.17071986198425292969e+00) (13, 1.38275945186614990234e+00) (14, 1.10589587688446044922e+00) (15, 1.13772869110107421875e+00) (16, 1.25326907634735107422e+00) (17, -5.99540996551513671875e+00) (0, 2.44387006759643554688e+00) (1, 1.88636279106140136719e+00) (2, 2.34491586685180664062e+00) (3, 1.71579992771148681641e+00) (4, 2.07268619537353515625e+00) (5, -1.63040530681610107422e+00) (6, -2.16881918907165527344e+00) (7, -1.54701769351959228516e+00) (8, -7.73704111576080322266e-01) (9, 3.36600303649902343750e+00) (10, 1.19175946712493896484e+00) (11, 2.33280777931213378906e+00) (12, 1.44769477844238281250e+00) (13, 3.05570030212402343750e+00) (14, 1.85061550140380859375e+00) (15, 2.00091600418090820312e+00) (16, 1.60818874835968017578e+00) (17, -5.86850357055664062500e+00) (18, 2.33011150360107421875e+00) (19, -1.88873183727264404297e+00) (20, 1.38863170146942138672e+00) (21, 2.65469694137573242188e+00) (22, -1.80153012275695800781e+00) (18, 5.70611511230468750000e+02) (19, -3.88470420837402343750e+01) (20, 1.50000000000000000000e+03) (21, 3.11384487152099609375e+01) (22, -3.88344993591308593750e+01) (18, 1.50000000000000000000e+03) (19, -2.85850296020507812500e+01) (20, 1.50000000000000000000e+03) (21, 4.34396095275878906250e+01) (22, -2.88551635742187500000e+01) (18, 1.50000000000000000000e+03) (19, -1.17974615097045898438e+01) (20, 1.50000000000000000000e+03) (21, 4.09400749206542968750e+01) (22, -1.50789690017700195312e+01) (23, 1.02710685729980468750e+01) (24, 6.11147224903106689453e-01) (25, 1.32215416431427001953e+00) (26, 1.26173138618469238281e+00) (27, 1.36019086837768554688e+00) 
