FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=18 5 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 5.37787361145019531250e+01) (1, 4.42651405334472656250e+01) (2, 3.40137710571289062500e+01) (3, -4.95467498779296875000e+02) (4, 5.08026313781738281250e+01) (5, 1.45155419921875000000e+03) (6, 9.03581848144531250000e+02) (7, 1.46904211425781250000e+03) (8, 1.49805065917968750000e+03) (9, 3.54009857177734375000e+01) (10, 3.53862228393554687500e+01) (11, 3.73963851928710937500e+01) (12, 3.82344360351562500000e+01) (13, 3.34033584594726562500e+01) (14, 3.41819496154785156250e+01) (15, 3.30389831542968750000e+02) (16, 1.49166674804687500000e+03) (17, 4.85729265213012695312e+00) (0, 9.44437563419342041016e-01) (1, 8.14445793628692626953e-01) (2, 9.28331732749938964844e-01) (3, 1.47861599922180175781e+00) (4, 7.62296915054321289062e-01) (5, -1.21369910240173339844e+00) (6, -1.80923581123352050781e+00) (7, -1.53146815299987792969e+00) (8, -2.34669484198093414307e-02) (9, 1.00274670124053955078e+00) (10, 1.07792103290557861328e+00) (11, 1.05652534961700439453e+00) (12, 9.69978272914886474609e-01) (13, 1.10752630233764648438e+00) (14, 1.04242265224456787109e+00) (15, 1.47613477706909179688e+00) (16, 1.23874104022979736328e+00) (17, -5.23346662521362304688e+00) (0, 1.23677015304565429688e+00) (1, 1.36690199375152587891e+00) (2, 1.12995707988739013672e+00) (3, 9.26508009433746337891e-01) (4, 1.14416182041168212891e+00) (5, -7.58759677410125732422e-01) (6, -6.55367732048034667969e-01) (7, -7.30926454067230224609e-01) (8, 4.62057739496231079102e-02) (9, 1.05034911632537841797e+00) (10, 1.19239234924316406250e+00) (11, 1.18779861927032470703e+00) (12, 1.18406569957733154297e+00) (13, 1.17313814163208007812e+00) (14, 1.08601617813110351562e+00) (15, 7.87925899028778076172e-01) (16, 1.07738924026489257812e+00) (17, -4.71017742156982421875e+00) (0, 8.09867401123046875000e+01) (1, 6.57682647705078125000e+01) (2, 6.02817420959472656250e+01) (3, -4.69859680175781250000e+02) (4, 8.01279525756835937500e+01) (5, 1.45156005859375000000e+03) (6, 1.22452600097656250000e+03) (7, 1.42635656738281250000e+03) (8, 1.49789624023437500000e+03) (9, 4.61742973327636718750e+01) (10, 4.59685287475585937500e+01) (11, 4.81621589660644531250e+01) (12, 4.91080780029296875000e+01) (13, 5.05161132812500000000e+01) (14, 4.72791633605957031250e+01) (15, 7.23785217285156250000e+02) (16, 1.49118750000000000000e+03) (17, 2.39638590812683105469e+00) (18, -8.07005524635314941406e-01) (19, 2.23138465881347656250e+01) (20, 6.60034513473510742188e+00) (21, -6.81382775306701660156e-01) (22, -7.73638844490051269531e-01) (18, -1.20848393440246582031e+00) (19, 2.17555618286132812500e+00) (20, 3.09575271606445312500e+00) (21, -1.21782493591308593750e+00) (22, -1.21708607673645019531e+00) (18, 7.17823088169097900391e-01) (19, 1.50000000000000000000e+03) (20, 1.50000000000000000000e+03) (21, 8.47819745540618896484e-01) (22, 8.56899678707122802734e-01) (18, 8.61710011959075927734e-01) (19, 1.50000000000000000000e+03) (20, 1.50000000000000000000e+03) (21, 8.07512342929840087891e-01) (22, 8.69250595569610595703e-01) (23, 3.76382493972778320312e+00) (24, 9.05703449249267578125e+00) (25, 8.53193819522857666016e-01) (26, 7.97380626201629638672e-01) (27, 8.37510406970977783203e-01) 
