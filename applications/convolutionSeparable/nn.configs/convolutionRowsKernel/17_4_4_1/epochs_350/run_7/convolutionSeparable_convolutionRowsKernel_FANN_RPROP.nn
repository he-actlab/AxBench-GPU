FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=18 5 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -7.63156604766845703125e+00) (1, 3.75760078430175781250e+01) (2, -1.83018636703491210938e+00) (3, -2.89215445518493652344e-01) (4, -1.55178105831146240234e+00) (5, 1.12369165420532226562e+01) (6, 8.50949001312255859375e+00) (7, 5.27676773071289062500e+01) (8, 1.42532169818878173828e+00) (9, 4.59884796142578125000e+01) (10, 3.62565922737121582031e+00) (11, 5.38274526596069335938e+00) (12, 4.42013978958129882812e+00) (13, 1.28482794761657714844e+00) (14, 5.75398063659667968750e+00) (15, 1.51290428638458251953e+00) (16, -2.55492830276489257812e+00) (17, -1.04850715637207031250e+02) (0, -2.69257946014404296875e+01) (1, 3.55433959960937500000e+01) (2, -2.68850147724151611328e-01) (3, 3.46595078706741333008e-01) (4, -1.03816461563110351562e+00) (5, 2.98829793930053710938e+00) (6, 2.58083362579345703125e+01) (7, 1.96058952808380126953e+00) (8, 2.98418939113616943359e-01) (9, 9.12541732788085937500e+01) (10, 3.81076383590698242188e+00) (11, 2.33423280715942382812e+00) (12, 4.12524557113647460938e+00) (13, 5.49585640430450439453e-01) (14, 2.12461686134338378906e+00) (15, 8.86844348907470703125e+00) (16, 8.83020579814910888672e-01) (17, -1.05539848327636718750e+02) (0, 2.08602404594421386719e+00) (1, 2.88052511215209960938e+00) (2, 2.22031331062316894531e+00) (3, 1.91151833534240722656e+00) (4, 2.48760151863098144531e+00) (5, -9.63642477989196777344e-01) (6, -3.07057619094848632812e+00) (7, -3.28695034980773925781e+00) (8, -4.45811040699481964111e-02) (9, 1.94655907154083251953e+00) (10, 2.35393071174621582031e+00) (11, 2.14805555343627929688e+00) (12, 4.11833524703979492188e+00) (13, 6.52406990528106689453e-01) (14, 1.03409552574157714844e+00) (15, 2.73388719558715820312e+00) (16, 2.12201619148254394531e+00) (17, -1.30600461959838867188e+01) (0, -2.62525848388671875000e+02) (1, -3.00798248291015625000e+02) (2, -1.17575225830078125000e+02) (3, -5.36349906921386718750e+01) (4, -1.19413063049316406250e+02) (5, -9.62327346801757812500e+01) (6, -7.86745727539062500000e+02) (7, -4.10076263427734375000e+02) (8, -1.31430328369140625000e+02) (9, 8.33137989044189453125e+00) (10, -1.00069313049316406250e+01) (11, -3.31503540039062500000e+02) (12, -2.74350250244140625000e+02) (13, 2.78692871093750000000e+02) (14, 7.51134567260742187500e+01) (15, 2.33988662719726562500e+02) (16, 2.34762878417968750000e+02) (17, 9.19742323458194732666e-03) (18, 1.50000000000000000000e+03) (19, 1.50000000000000000000e+03) (20, 1.50000000000000000000e+03) (21, 1.69229245185852050781e+00) (22, -4.67365264892578125000e-01) (18, 1.50000000000000000000e+03) (19, 1.50000000000000000000e+03) (20, 1.65442947387695312500e+02) (21, -5.32352924346923828125e-01) (22, -1.36946821212768554688e+00) (18, 1.50000000000000000000e+03) (19, 1.50000000000000000000e+03) (20, 1.50000000000000000000e+03) (21, 1.65190649032592773438e+00) (22, -4.44138050079345703125e-01) (18, 1.50000000000000000000e+03) (19, 1.50000000000000000000e+03) (20, 1.50000000000000000000e+03) (21, -1.91675350069999694824e-01) (22, -1.18039095401763916016e+00) (23, 1.38477945327758789062e+00) (24, 5.10468959808349609375e+00) (25, 1.39579582214355468750e+00) (26, 1.31152808666229248047e+00) (27, 1.55136072635650634766e+00) 
