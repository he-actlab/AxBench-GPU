FANN_FLO_2.1
num_layers=4
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=18 5 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (5, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 9.32955980300903320312e-01) (1, -3.79953324794769287109e-01) (2, 1.95047581195831298828e+00) (3, 1.52764081954956054688e+00) (4, 1.86905479431152343750e+00) (5, 3.28681921958923339844e+00) (6, 4.41205835342407226562e+00) (7, 3.10243964195251464844e+00) (8, 2.65445613861083984375e+00) (9, 9.47476100921630859375e+00) (10, 1.50068449974060058594e+00) (11, -3.94709318876266479492e-01) (12, 1.33586609363555908203e+00) (13, 2.91167116165161132812e+00) (14, 3.41773581504821777344e+00) (15, 1.87997436523437500000e+00) (16, 2.49029254913330078125e+00) (17, 4.47714757919311523438e+00) (0, 4.65393483638763427734e-01) (1, 5.40220439434051513672e-01) (2, 4.66247230768203735352e-01) (3, 4.37239319086074829102e-01) (4, 3.81225258111953735352e-01) (5, -7.40592598915100097656e-01) (6, -7.29559481143951416016e-01) (7, -7.26542890071868896484e-01) (8, -1.17484554648399353027e-02) (9, 1.25907838344573974609e-01) (10, 3.59994441270828247070e-01) (11, 1.08379614353179931641e+00) (12, 3.23516577482223510742e-01) (13, 4.50330704450607299805e-01) (14, -2.55236089229583740234e-01) (15, 2.17811703681945800781e-01) (16, 4.29028600454330444336e-01) (17, -2.12062454223632812500e+00) (0, 8.26889455318450927734e-01) (1, 6.15430355072021484375e-01) (2, 3.89633536338806152344e-01) (3, 6.54382169246673583984e-01) (4, 6.79224967956542968750e-01) (5, -1.21659600734710693359e+00) (6, -1.13447260856628417969e+00) (7, -5.26943504810333251953e-01) (8, -1.69095285236835479736e-02) (9, 1.92245170474052429199e-01) (10, 5.20979523658752441406e-01) (11, 6.62367403507232666016e-01) (12, 5.86645722389221191406e-01) (13, 4.35105323791503906250e-01) (14, 2.51435130834579467773e-01) (15, 3.87336820363998413086e-01) (16, 7.31525897979736328125e-01) (17, -1.50616872310638427734e+00) (0, 6.93208515644073486328e-01) (1, 7.63971030712127685547e-01) (2, 8.04287135601043701172e-01) (3, 7.78370857238769531250e-01) (4, 7.43214607238769531250e-01) (5, -5.56667566299438476562e-01) (6, -6.90517306327819824219e-01) (7, -6.88556492328643798828e-01) (8, 2.64414399862289428711e-03) (9, 8.89646470546722412109e-01) (10, 7.84278929233551025391e-01) (11, 6.77850365638732910156e-01) (12, 7.68791019916534423828e-01) (13, 8.02442908287048339844e-01) (14, 8.94406795501708984375e-01) (15, 8.20731103420257568359e-01) (16, 7.47469365596771240234e-01) (17, -3.99311447143554687500e+00) (18, 9.82558548450469970703e-01) (19, 1.38860635757446289062e+01) (20, 1.16063508987426757812e+01) (21, 3.14498901367187500000e+01) (22, 9.10724818706512451172e-01) (18, -1.56634700298309326172e+00) (19, 6.26547873020172119141e-01) (20, 2.41205406188964843750e+00) (21, 1.28294010162353515625e+01) (22, -1.49449408054351806641e+00) (18, -2.15599393844604492188e+00) (19, 6.60747468471527099609e-01) (20, 9.82967078685760498047e-01) (21, 5.60214853286743164062e+00) (22, -2.25951313972473144531e+00) (18, 8.57674360275268554688e-01) (19, 1.40118341445922851562e+01) (20, 1.14885282516479492188e+01) (21, 3.15974750518798828125e+01) (22, 8.75266492366790771484e-01) (23, 9.89699661731719970703e-01) (24, 4.44756460189819335938e+00) (25, 7.54248714447021484375e+00) (26, 9.64693009853363037109e-01) (27, 9.48463022708892822266e-01) 
