FANN_FLO_2.1
num_layers=3
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=18 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -4.94838142395019531250e+01) (1, 7.77820587158203125000e+01) (2, 1.06970682144165039062e+01) (3, 3.69643249511718750000e+01) (4, 2.16753406524658203125e+01) (5, -7.04280700683593750000e+01) (6, -3.92383232116699218750e+01) (7, -3.91573371887207031250e+01) (8, -1.54989013671875000000e+01) (9, 3.00404148101806640625e+01) (10, 1.60892047882080078125e+01) (11, 3.07472286224365234375e+01) (12, 3.01123676300048828125e+01) (13, 1.43450832366943359375e+01) (14, 3.06379814147949218750e+01) (15, 3.04737892150878906250e+01) (16, 3.15439987182617187500e+01) (17, 1.28579521179199218750e+00) (0, 1.20411229133605957031e+00) (1, 1.38273537158966064453e+00) (2, 1.03674101829528808594e+00) (3, 1.39114260673522949219e+00) (4, 1.00808739662170410156e+00) (5, -1.16167593002319335938e+00) (6, -9.85831379890441894531e-01) (7, -1.48246741294860839844e+00) (8, 1.31826847791671752930e-01) (9, 1.25086879730224609375e+00) (10, 1.45092797279357910156e+00) (11, 1.20967268943786621094e+00) (12, 1.23103427886962890625e+00) (13, 1.21252024173736572266e+00) (14, 1.18580245971679687500e+00) (15, 1.26751923561096191406e+00) (16, 1.19463562965393066406e+00) (17, -3.70317316055297851562e+00) (0, 1.13098418712615966797e+00) (1, 8.74859035015106201172e-01) (2, 1.04423093795776367188e+00) (3, 1.06263232231140136719e+00) (4, 1.00204753875732421875e+00) (5, -9.20684933662414550781e-01) (6, -1.33105814456939697266e+00) (7, -7.68268227577209472656e-01) (8, -2.36524883657693862915e-02) (9, 9.58286643028259277344e-01) (10, 9.29218053817749023438e-01) (11, 9.41271781921386718750e-01) (12, 1.07311832904815673828e+00) (13, 1.03856849670410156250e+00) (14, 9.66579854488372802734e-01) (15, 1.02130234241485595703e+00) (16, 1.06651902198791503906e+00) (17, -5.98097133636474609375e+00) (0, -5.12599563598632812500e+01) (1, 8.21652145385742187500e+01) (2, 1.09611988067626953125e+01) (3, 3.68088035583496093750e+01) (4, 2.01025009155273437500e+01) (5, -7.07773895263671875000e+01) (6, -3.94175910949707031250e+01) (7, -3.92136535644531250000e+01) (8, -1.55550441741943359375e+01) (9, 2.99939346313476562500e+01) (10, 1.60915622711181640625e+01) (11, 3.07717208862304687500e+01) (12, 3.01320171356201171875e+01) (13, 1.43565578460693359375e+01) (14, 3.06568775177001953125e+01) (15, 3.05145187377929687500e+01) (16, 3.15123195648193359375e+01) (17, 1.32749938964843750000e+00) (18, 8.62994968891143798828e-01) (19, 5.77154207229614257812e+00) (20, 7.21953010559082031250e+00) (21, 9.09580826759338378906e-01) (22, 8.34910511970520019531e-01) 
