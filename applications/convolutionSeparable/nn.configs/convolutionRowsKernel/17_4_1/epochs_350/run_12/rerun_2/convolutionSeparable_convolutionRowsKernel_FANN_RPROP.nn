FANN_FLO_2.1
num_layers=3
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=18 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 5.07324028015136718750e+01) (1, 3.31456909179687500000e+02) (2, 9.34963531494140625000e+01) (3, 9.19353408813476562500e+01) (4, 1.50000000000000000000e+03) (5, -1.01346435546875000000e+02) (6, -5.41211013793945312500e+01) (7, -2.10457168579101562500e+02) (8, -1.22633819580078125000e+02) (9, 2.15900993347167968750e+01) (10, 1.01729080200195312500e+02) (11, 7.60756454467773437500e+01) (12, 9.16041488647460937500e+01) (13, 9.35851211547851562500e+01) (14, 9.36166915893554687500e+01) (15, 4.20443916320800781250e+01) (16, 4.23210029602050781250e+01) (17, 8.33605825901031494141e-01) (0, 1.01789820194244384766e+00) (1, 8.16134512424468994141e-01) (2, 6.86755716800689697266e-01) (3, 5.51984667778015136719e-01) (4, 5.94270229339599609375e-01) (5, -4.69413697719573974609e-01) (6, -6.75144851207733154297e-01) (7, -1.04358762502670288086e-01) (8, 1.07916191220283508301e-01) (9, 6.94027662277221679688e-01) (10, 7.43740558624267578125e-01) (11, 7.42955863475799560547e-01) (12, 6.85566008090972900391e-01) (13, 8.67703139781951904297e-01) (14, 6.66566312313079833984e-01) (15, 7.83845126628875732422e-01) (16, 9.13170576095581054688e-01) (17, -3.20077848434448242188e+00) (0, 6.22759342193603515625e-01) (1, 5.82242608070373535156e-01) (2, 7.83173024654388427734e-01) (3, 8.32924842834472656250e-01) (4, 9.98376727104187011719e-01) (5, -1.14472508430480957031e+00) (6, -3.11579197645187377930e-01) (7, -1.49343049526214599609e+00) (8, 4.63754646480083465576e-02) (9, 7.83270895481109619141e-01) (10, 6.59541308879852294922e-01) (11, 5.71249067783355712891e-01) (12, 5.98166286945343017578e-01) (13, 4.96445655822753906250e-01) (14, 7.31737494468688964844e-01) (15, 7.05976128578186035156e-01) (16, 6.35329961776733398438e-01) (17, -2.64828395843505859375e+00) (0, 3.44703972339630126953e-01) (1, 6.28402888774871826172e-01) (2, 5.40208637714385986328e-01) (3, 6.98661804199218750000e-01) (4, 4.25549566745758056641e-01) (5, -4.51178967952728271484e-01) (6, -1.24941229820251464844e+00) (7, -6.40422046184539794922e-01) (8, -2.31172457337379455566e-01) (9, 6.05058908462524414062e-01) (10, 6.26950562000274658203e-01) (11, 7.80901789665222167969e-01) (12, 8.06415677070617675781e-01) (13, 6.68943166732788085938e-01) (14, 6.76215350627899169922e-01) (15, 5.50178110599517822266e-01) (16, 3.84838044643402099609e-01) (17, -2.64100909233093261719e+00) (18, 8.25086116790771484375e-01) (19, 5.50349664688110351562e+00) (20, 3.91676592826843261719e+00) (21, 3.81632494926452636719e+00) (22, 9.45470809936523437500e-01) 
