FANN_FLO_2.1
num_layers=3
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=18 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.15863871574401855469e+00) (1, 9.15956497192382812500e-01) (2, 8.91883075237274169922e-01) (3, 1.32036614418029785156e+00) (4, 6.14831387996673583984e-01) (5, -3.06908667087554931641e-01) (6, -1.42131507396697998047e+00) (7, -1.12434601783752441406e+00) (8, 3.69179219007492065430e-01) (9, 9.63786363601684570312e-01) (10, 1.20313572883605957031e+00) (11, 1.16985630989074707031e+00) (12, 8.76900970935821533203e-01) (13, 1.18674659729003906250e+00) (14, 1.05956470966339111328e+00) (15, 1.17267405986785888672e+00) (16, 8.29177141189575195312e-01) (17, -2.79452657699584960938e+00) (0, 6.59419476985931396484e-01) (1, 7.37365722656250000000e-01) (2, 7.73886084556579589844e-01) (3, 6.52594983577728271484e-01) (4, 9.84825253486633300781e-01) (5, -1.12552082538604736328e+00) (6, -5.06473481655120849609e-01) (7, -6.02701067924499511719e-01) (8, -3.64800900220870971680e-01) (9, 7.02025711536407470703e-01) (10, 5.89031040668487548828e-01) (11, 6.88806653022766113281e-01) (12, 6.65866911411285400391e-01) (13, 7.52838075160980224609e-01) (14, 6.24704897403717041016e-01) (15, 8.31933200359344482422e-01) (16, 7.20713019371032714844e-01) (17, -3.91619777679443359375e+00) (0, 5.31369628906250000000e+01) (1, 2.46038017272949218750e+01) (2, 2.42423324584960937500e+01) (3, 2.59986648559570312500e+01) (4, 1.71301794052124023438e+00) (5, -1.32291610717773437500e+02) (6, -3.23865547180175781250e+01) (7, -3.26274147033691406250e+01) (8, -1.41267883300781250000e+02) (9, 5.21223878860473632812e+00) (10, 3.55176277160644531250e+01) (11, 6.36058273315429687500e+01) (12, 1.15014572143554687500e+02) (13, 3.72428779602050781250e+01) (14, 8.03258666992187500000e+01) (15, 1.28234481811523437500e+02) (16, 2.25279865264892578125e+01) (17, 1.26486766338348388672e+00) (0, 6.34935021400451660156e-01) (1, 6.54739499092102050781e-01) (2, 6.59086525440216064453e-01) (3, 5.99514901638031005859e-01) (4, 5.57570815086364746094e-01) (5, -5.51166772842407226562e-01) (6, -7.13973045349121093750e-01) (7, -8.19062769412994384766e-01) (8, 3.92223715782165527344e-01) (9, 7.06241965293884277344e-01) (10, 6.92083597183227539062e-01) (11, 6.67481124401092529297e-01) (12, 7.36816823482513427734e-01) (13, 6.14789426326751708984e-01) (14, 6.80240809917449951172e-01) (15, 4.49427813291549682617e-01) (16, 7.10216164588928222656e-01) (17, -3.87037491798400878906e+00) (18, 4.81226110458374023438e+00) (19, 7.18757963180541992188e+00) (20, 2.27716386318206787109e-01) (21, 3.30256867408752441406e+00) (22, 1.38646960258483886719e+00) 
