FANN_FLO_2.1
num_layers=3
learning_rate=0.500000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=18 5 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (18, 3, 5.00000000000000000000e-01) (0, 3, 0.00000000000000000000e+00) (5, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 8.17838058471679687500e+01) (1, 7.83934402465820312500e+01) (2, 7.90297698974609375000e+01) (3, 9.17227859497070312500e+01) (4, 2.97111396789550781250e+01) (5, -1.52218444824218750000e+02) (6, -6.91086730957031250000e+01) (7, -1.16909225463867187500e+02) (8, -2.04850788116455078125e+01) (9, 4.70121765136718750000e+01) (10, 4.69484634399414062500e+01) (11, 6.07756233215332031250e+01) (12, 4.80214309692382812500e+01) (13, 4.20455474853515625000e+01) (14, 7.68643493652343750000e+01) (15, 5.20667304992675781250e+01) (16, 4.32484664916992187500e+01) (17, 1.00277101993560791016e+00) (0, 7.75399856567382812500e+01) (1, 8.49262695312500000000e+01) (2, 8.48544769287109375000e+01) (3, 8.29801177978515625000e+01) (4, 2.95066089630126953125e+01) (5, -4.32762756347656250000e+02) (6, -1.27700317382812500000e+02) (7, -1.18230903625488281250e+02) (8, -1.33432254791259765625e+01) (9, 4.26722221374511718750e+01) (10, 4.54894294738769531250e+01) (11, 4.55181503295898437500e+01) (12, 4.63385162353515625000e+01) (13, 4.15675926208496093750e+01) (14, 2.59489078521728515625e+01) (15, 3.85466461181640625000e+01) (16, 3.25394897460937500000e+01) (17, 3.88239979743957519531e-01) (0, 8.18351364135742187500e+01) (1, 7.84182968139648437500e+01) (2, 7.91136093139648437500e+01) (3, 9.17390823364257812500e+01) (4, 2.98026428222656250000e+01) (5, -1.51812957763671875000e+02) (6, -6.90473785400390625000e+01) (7, -1.16807586669921875000e+02) (8, -1.95615921020507812500e+01) (9, 4.71189689636230468750e+01) (10, 4.70227508544921875000e+01) (11, 6.05709266662597656250e+01) (12, 4.81426506042480468750e+01) (13, 4.20449371337890625000e+01) (14, 7.68686599731445312500e+01) (15, 5.19770317077636718750e+01) (16, 4.29931297302246093750e+01) (17, 9.59920525550842285156e-01) (0, 6.97190582752227783203e-01) (1, 7.10472166538238525391e-01) (2, 6.70118629932403564453e-01) (3, 7.41032123565673828125e-01) (4, 6.46727740764617919922e-01) (5, -5.63265204429626464844e-01) (6, -7.59781956672668457031e-01) (7, -6.06988549232482910156e-01) (8, -9.93245467543601989746e-03) (9, 7.58558213710784912109e-01) (10, 6.88987493515014648438e-01) (11, 7.49219477176666259766e-01) (12, 7.52874672412872314453e-01) (13, 7.09562301635742187500e-01) (14, 6.67553305625915527344e-01) (15, 7.35774159431457519531e-01) (16, 7.61224329471588134766e-01) (17, -3.17743229866027832031e+00) (18, 6.86196923255920410156e-01) (19, 1.49330884218215942383e-01) (20, 6.21634542942047119141e-01) (21, 1.24971780776977539062e+01) (22, 1.02524232864379882812e+00) 
